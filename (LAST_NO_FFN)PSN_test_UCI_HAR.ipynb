{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TRU2lkv-Ya_1",
        "outputId": "538aa822-1385-43a7-95dd-06b3163720ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.12/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: ptflops in /usr/local/lib/python3.12/dist-packages (0.7.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->thop) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->thop) (3.0.3)\n",
            "================================================================================\n",
            "PSN (Parametric Spectral Network) - Modified Training\n",
            "================================================================================\n",
            "Device: cuda\n",
            "\n",
            "================================================================================\n",
            "Loading UCI-HAR Dataset\n",
            "================================================================================\n",
            "\n",
            "############################################################\n",
            "Loading UCI-HAR...\n",
            "############################################################\n",
            "Train: (7352, 128, 9) | Classes: 6\n",
            "Test: (2947, 128, 9) | Classes: 6\n",
            "Activity Names: ['Walking', 'Walking Upstairs', 'Walking Downstairs', 'Sitting', 'Standing', 'Laying']\n",
            "Train class distribution: {np.int64(0): 1226, np.int64(1): 1073, np.int64(2): 986, np.int64(3): 1286, np.int64(4): 1374, np.int64(5): 1407}\n",
            "Test class distribution: {np.int64(0): 496, np.int64(1): 471, np.int64(2): 420, np.int64(3): 491, np.int64(4): 532, np.int64(5): 537}\n",
            "\n",
            "================================================================================\n",
            "Successfully loaded 1 datasets\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2073712744.py:409: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training UCI-HAR with Modified PSN\n",
            "============================================================\n",
            "Params: 0.23M | FLOPs: 18.51M | Inf: 5.67ms\n",
            "Input: (128, 9) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.001000   0.9253     0.9050     0.9056     0.9063     0.9071     (*)\n",
            "2        0.000999   0.5516     0.9233     0.9243     0.9254     0.9247     (*)\n",
            "3        0.000998   0.5204     0.9206     0.9220     0.9218     0.9229    \n",
            "4        0.000996   0.5131     0.9250     0.9256     0.9274     0.9263     (*)\n",
            "5        0.000994   0.5091     0.9342     0.9352     0.9365     0.9357     (*)\n",
            "6        0.000991   0.5076     0.9301     0.9311     0.9342     0.9314    \n",
            "7        0.000988   0.5054     0.9403     0.9415     0.9413     0.9419     (*)\n",
            "8        0.000984   0.5047     0.9267     0.9274     0.9313     0.9279    \n",
            "9        0.000980   0.5016     0.9342     0.9349     0.9403     0.9351    \n",
            "10       0.000976   0.4959     0.9410     0.9417     0.9455     0.9418     (*)\n",
            "11       0.000970   0.4874     0.9505     0.9514     0.9511     0.9520     (*)\n",
            "12       0.000965   0.4866     0.9505     0.9512     0.9523     0.9514    \n",
            "13       0.000959   0.4782     0.9508     0.9512     0.9517     0.9515     (*)\n",
            "14       0.000952   0.5052     0.9277     0.9276     0.9313     0.9273    \n",
            "15       0.000946   0.4802     0.9427     0.9429     0.9461     0.9427    \n",
            "16       0.000938   0.4728     0.9484     0.9489     0.9510     0.9489    \n",
            "17       0.000930   0.4635     0.9528     0.9533     0.9548     0.9535     (*)\n",
            "18       0.000922   0.4637     0.9454     0.9458     0.9461     0.9464    \n",
            "19       0.000914   0.4566     0.9318     0.9329     0.9328     0.9338    \n",
            "20       0.000905   0.4592     0.9454     0.9463     0.9467     0.9465    \n",
            "21       0.000895   0.4549     0.9355     0.9366     0.9366     0.9375    \n",
            "22       0.000885   0.4520     0.9440     0.9449     0.9449     0.9454    \n",
            "23       0.000875   0.4511     0.9522     0.9526     0.9534     0.9529    \n",
            "24       0.000864   0.4463     0.9477     0.9483     0.9489     0.9486    \n",
            "25       0.000854   0.4501     0.9437     0.9443     0.9465     0.9443    \n",
            "26       0.000842   0.4503     0.9522     0.9524     0.9550     0.9526    \n",
            "27       0.000831   0.4457     0.9444     0.9446     0.9484     0.9447    \n",
            "28       0.000819   0.4553     0.9586     0.9590     0.9617     0.9588     (*)\n",
            "29       0.000806   0.4558     0.9464     0.9459     0.9497     0.9466    \n",
            "30       0.000794   0.4468     0.9488     0.9493     0.9491     0.9500    \n",
            "31       0.000781   0.4426     0.9498     0.9499     0.9505     0.9505    \n",
            "32       0.000768   0.4385     0.9437     0.9438     0.9443     0.9446    \n",
            "33       0.000755   0.4409     0.9382     0.9381     0.9441     0.9385    \n",
            "34       0.000741   0.4426     0.9477     0.9476     0.9490     0.9483    \n",
            "35       0.000727   0.4354     0.9535     0.9538     0.9542     0.9543    \n",
            "36       0.000713   0.4417     0.9518     0.9519     0.9531     0.9524    \n",
            "37       0.000699   0.4382     0.9505     0.9505     0.9531     0.9508    \n",
            "38       0.000684   0.4381     0.9532     0.9534     0.9538     0.9539    \n",
            "39       0.000669   0.4334     0.9532     0.9537     0.9546     0.9540    \n",
            "40       0.000655   0.4319     0.9508     0.9512     0.9532     0.9513    \n",
            "41       0.000639   0.4342     0.9525     0.9527     0.9565     0.9528    \n",
            "42       0.000624   0.4328     0.9549     0.9550     0.9557     0.9555    \n",
            "43       0.000609   0.4310     0.9528     0.9531     0.9543     0.9534    \n",
            "44       0.000594   0.4355     0.9511     0.9517     0.9523     0.9520    \n",
            "45       0.000578   0.4316     0.9488     0.9494     0.9504     0.9496    \n",
            "46       0.000563   0.4318     0.9539     0.9542     0.9545     0.9547    \n",
            "47       0.000547   0.4305     0.9515     0.9515     0.9522     0.9521    \n",
            "48       0.000531   0.4308     0.9552     0.9556     0.9567     0.9558    \n",
            "49       0.000516   0.4298     0.9484     0.9488     0.9495     0.9493    \n",
            "50       0.000500   0.4298     0.9542     0.9542     0.9559     0.9546    \n",
            "51       0.000484   0.4291     0.9518     0.9523     0.9532     0.9525    \n",
            "52       0.000469   0.4304     0.9576     0.9579     0.9583     0.9583    \n",
            "53       0.000453   0.4321     0.9552     0.9552     0.9562     0.9556    \n",
            "54       0.000437   0.4301     0.9539     0.9539     0.9546     0.9544    \n",
            "55       0.000422   0.4282     0.9535     0.9537     0.9547     0.9541    \n",
            "56       0.000406   0.4274     0.9528     0.9530     0.9543     0.9534    \n",
            "57       0.000391   0.4274     0.9505     0.9508     0.9526     0.9510    \n",
            "58       0.000376   0.4271     0.9481     0.9483     0.9505     0.9486    \n",
            "59       0.000361   0.4274     0.9545     0.9550     0.9557     0.9553    \n",
            "60       0.000345   0.4290     0.9549     0.9553     0.9565     0.9555    \n",
            "61       0.000331   0.4268     0.9491     0.9493     0.9523     0.9495    \n",
            "62       0.000316   0.4279     0.9488     0.9487     0.9527     0.9490    \n",
            "63       0.000301   0.4283     0.9525     0.9528     0.9535     0.9532    \n",
            "64       0.000287   0.4285     0.9542     0.9545     0.9551     0.9549    \n",
            "65       0.000273   0.4278     0.9559     0.9562     0.9571     0.9565    \n",
            "66       0.000259   0.4271     0.9532     0.9535     0.9547     0.9538    \n",
            "67       0.000245   0.4265     0.9511     0.9517     0.9528     0.9519    \n",
            "68       0.000232   0.4265     0.9535     0.9539     0.9557     0.9540    \n",
            "69       0.000219   0.4269     0.9545     0.9549     0.9572     0.9550    \n",
            "70       0.000206   0.4264     0.9545     0.9550     0.9560     0.9553    \n",
            "71       0.000194   0.4263     0.9555     0.9560     0.9575     0.9561    \n",
            "72       0.000181   0.4261     0.9552     0.9557     0.9569     0.9559    \n",
            "73       0.000169   0.4259     0.9559     0.9563     0.9572     0.9566    \n",
            "74       0.000158   0.4260     0.9552     0.9557     0.9572     0.9558    \n",
            "75       0.000146   0.4260     0.9552     0.9556     0.9569     0.9558    \n",
            "76       0.000136   0.4261     0.9562     0.9566     0.9580     0.9568    \n",
            "77       0.000125   0.4259     0.9572     0.9576     0.9591     0.9578    \n",
            "78       0.000115   0.4258     0.9566     0.9570     0.9584     0.9571    \n",
            "79       0.000105   0.4258     0.9572     0.9577     0.9587     0.9579    \n",
            "80       0.000095   0.4261     0.9579     0.9583     0.9597     0.9584    \n",
            "81       0.000086   0.4260     0.9576     0.9580     0.9592     0.9581    \n",
            "82       0.000078   0.4259     0.9572     0.9577     0.9587     0.9579    \n",
            "83       0.000070   0.4258     0.9572     0.9577     0.9586     0.9579    \n",
            "84       0.000062   0.4259     0.9566     0.9571     0.9580     0.9572    \n",
            "85       0.000054   0.4258     0.9569     0.9574     0.9584     0.9575    \n",
            "86       0.000048   0.4258     0.9569     0.9574     0.9584     0.9575    \n",
            "87       0.000041   0.4258     0.9566     0.9570     0.9581     0.9572    \n",
            "88       0.000035   0.4259     0.9562     0.9567     0.9578     0.9569    \n",
            "89       0.000030   0.4259     0.9562     0.9567     0.9578     0.9569    \n",
            "90       0.000024   0.4258     0.9555     0.9560     0.9572     0.9562    \n",
            "91       0.000020   0.4259     0.9562     0.9567     0.9578     0.9569    \n",
            "92       0.000016   0.4257     0.9559     0.9564     0.9575     0.9565    \n",
            "93       0.000012   0.4257     0.9559     0.9564     0.9575     0.9565    \n",
            "94       0.000009   0.4259     0.9569     0.9574     0.9584     0.9575    \n",
            "95       0.000006   0.4257     0.9569     0.9574     0.9584     0.9575    \n",
            "96       0.000004   0.4259     0.9569     0.9574     0.9584     0.9575    \n",
            "97       0.000002   0.4259     0.9569     0.9574     0.9584     0.9575    \n",
            "98       0.000001   0.4258     0.9569     0.9574     0.9584     0.9575    \n",
            "99       0.000000   0.4258     0.9569     0.9574     0.9584     0.9575    \n",
            "100      0.000000   0.4258     0.9569     0.9574     0.9584     0.9575    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9586 | F1: 0.9590 | Prec: 0.9617 | Rec: 0.9588\n",
            "Params: 0.23M | FLOPs: 18.51M | Inf: 5.67ms\n",
            "\n",
            "Generating t-SNE plot for UCI-HAR...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2073712744.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             result = train_single_dataset(\n\u001b[0m\u001b[1;32m    524\u001b[0m                 \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mdataset_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2073712744.py\u001b[0m in \u001b[0;36mtrain_single_dataset\u001b[0;34m(dataset_name, X_train, y_train, X_test, y_test, activity_names, device, epochs)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0mcm_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{dataset_name}_PSN_confusion_matrix.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nGenerating t-SNE plot for {dataset_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0mplot_tsne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsne_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Generating Confusion Matrix for {dataset_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2073712744.py\u001b[0m in \u001b[0;36mplot_tsne\u001b[0;34m(features, labels, activity_names, save_path, samples_per_class)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_sampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mperplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mfeatures_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_sampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tab20'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params_vs_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0mdegrees_of_freedom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m         return self._tsne(\n\u001b[0m\u001b[1;32m   1047\u001b[0m             \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_iter_without_progress\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_without_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_divergence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopt_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0;31m# Save the final number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, max_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compute_error\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_convergence\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0minc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     error = _barnes_hut_tsne.gradient(\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mval_P\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install thop ptflops\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "from thop import profile\n",
        "from collections import Counter\n",
        "from glob import glob\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "from torch.cuda.amp import GradScaler\n",
        "\n",
        "class UCIHARDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = torch.FloatTensor(data)\n",
        "        self.labels = torch.LongTensor(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "def read_txt_matrix(file_path):\n",
        "    return np.loadtxt(file_path)\n",
        "\n",
        "def load_uci_har(root_path='/content/drive/MyDrive/HAR_Dataset/UCI'):\n",
        "    UCI_CHANNELS_PREFIX = [\n",
        "        \"total_acc_x_\", \"total_acc_y_\", \"total_acc_z_\",\n",
        "        \"body_acc_x_\", \"body_acc_y_\", \"body_acc_z_\",\n",
        "        \"body_gyro_x_\", \"body_gyro_y_\", \"body_gyro_z_\",\n",
        "    ]\n",
        "    def load_split(split):\n",
        "        channels = []\n",
        "        for prefix in UCI_CHANNELS_PREFIX:\n",
        "            file_path = os.path.join(root_path, f\"{prefix}{split}.txt\")\n",
        "            if not os.path.exists(file_path):\n",
        "                raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "            channels.append(read_txt_matrix(file_path))\n",
        "        X = np.stack(channels, axis=1)\n",
        "        y = read_txt_matrix(os.path.join(root_path, f\"y_{split}.txt\")).astype(int) - 1\n",
        "        return X, y\n",
        "    X_train, y_train = load_split('train')\n",
        "    X_test, y_test = load_split('test')\n",
        "    X_train = X_train.transpose(0, 2, 1)\n",
        "    X_test = X_test.transpose(0, 2, 1)\n",
        "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train_flat)\n",
        "    X_train_flat = scaler.transform(X_train_flat)\n",
        "    X_test_flat = scaler.transform(X_test_flat)\n",
        "    X_train = X_train_flat.reshape(X_train.shape)\n",
        "    X_test = X_test_flat.reshape(X_test.shape)\n",
        "    activity_names = ['Walking', 'Walking Upstairs', 'Walking Downstairs', 'Sitting', 'Standing', 'Laying']\n",
        "    return X_train, y_train.astype(np.int64), X_test, y_test.astype(np.int64), activity_names\n",
        "\n",
        "def load_wisdm_data(dataset_path=\"/content/drive/MyDrive/HAR_Dataset/WISDM\"):\n",
        "    return None, None, None, None, None\n",
        "\n",
        "def load_opportunity_local_data(data_path=\"/content/drive/MyDrive/HAR_Dataset/OPPORTUNITY\", window_size=30, step=15):\n",
        "    return None, None, None, None, None\n",
        "\n",
        "def load_dsads_data(data_path, w_s=25, stride=12):\n",
        "    return None, None, None, None, None\n",
        "\n",
        "def load_pamap2_data(dataset_dir=\"/content/drive/MyDrive/HAR_Dataset/PAMAP2\"):\n",
        "    return None, None, None, None, None\n",
        "\n",
        "def load_mhealth_data(dataset_dir=\"/content/drive/MyDrive/HAR_Dataset/MHEALTH\"):\n",
        "    return None, None, None, None, None\n",
        "\n",
        "class LearnedAdaptiveSpectralTransform(nn.Module):\n",
        "    def __init__(self, seq_len, in_channels, num_basis=64):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.in_channels = in_channels\n",
        "        self.num_basis = num_basis\n",
        "        self.register_buffer('t', torch.arange(seq_len).float())\n",
        "        low_band = num_basis // 3\n",
        "        mid_band = num_basis // 3\n",
        "        high_band = num_basis - low_band - mid_band\n",
        "        freqs_low = torch.linspace(0, seq_len//8, low_band) / seq_len\n",
        "        freqs_mid = torch.linspace(seq_len//8, seq_len//4, mid_band) / seq_len\n",
        "        freqs_high = torch.linspace(seq_len//4, seq_len//2, high_band) / seq_len\n",
        "        init_freqs = torch.cat([freqs_low, freqs_mid, freqs_high])\n",
        "        self.frequencies = nn.Parameter(init_freqs)\n",
        "        self.phases = nn.Parameter(torch.zeros(num_basis))\n",
        "        self.channel_weights_real = nn.Parameter(torch.randn(in_channels, num_basis) * 0.02)\n",
        "        self.channel_weights_imag = nn.Parameter(torch.randn(in_channels, num_basis) * 0.02)\n",
        "        self.gamma = nn.Parameter(torch.ones(in_channels, 1))\n",
        "        self.beta = nn.Parameter(torch.zeros(in_channels, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, T = x.shape\n",
        "        args = 2 * np.pi * self.frequencies.unsqueeze(1) * self.t.unsqueeze(0) + self.phases.unsqueeze(1)\n",
        "        basis_real = torch.cos(args)\n",
        "        basis_imag = -torch.sin(args)\n",
        "        spectral_real = torch.einsum('bct,ft->bcf', x, basis_real)\n",
        "        spectral_imag = torch.einsum('bct,ft->bcf', x, basis_imag)\n",
        "        weighted_real = spectral_real * (1 + self.channel_weights_real.unsqueeze(0)) - \\\n",
        "                       spectral_imag * self.channel_weights_imag.unsqueeze(0)\n",
        "        weighted_imag = spectral_real * self.channel_weights_imag.unsqueeze(0) + \\\n",
        "                       spectral_imag * (1 + self.channel_weights_real.unsqueeze(0))\n",
        "        spectral_mag = torch.sqrt(weighted_real**2 + weighted_imag**2 + 1e-8)\n",
        "        spectral_mag = spectral_mag / math.sqrt(self.seq_len)\n",
        "        spectral_mag = spectral_mag * self.gamma.unsqueeze(0) + self.beta.unsqueeze(0)\n",
        "        return spectral_mag\n",
        "\n",
        "class SpectralAttention(nn.Module):\n",
        "    def __init__(self, num_basis, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = num_basis // num_heads\n",
        "        self.qkv = nn.Linear(num_basis, num_basis * 3)\n",
        "        self.proj = nn.Linear(num_basis, num_basis)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = nn.LayerNorm(num_basis)\n",
        "        self.temperature = nn.Parameter(torch.ones(1) * math.sqrt(self.head_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, F_dim = x.shape\n",
        "        outputs = []\n",
        "        for c in range(C):\n",
        "            x_c = x[:, c, :]\n",
        "            x_norm = self.norm(x_c)\n",
        "            qkv = self.qkv(x_norm).reshape(B, 3, self.num_heads, self.head_dim).permute(1, 0, 2, 3)\n",
        "            q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "            attn = (q @ k.transpose(-2, -1)) / self.temperature\n",
        "            attn = F.softmax(attn, dim=-1)\n",
        "            attn = self.dropout(attn)\n",
        "            out = (attn @ v).reshape(B, F_dim)\n",
        "            out = self.proj(out)\n",
        "            out = self.dropout(out)\n",
        "            out = out + x_c\n",
        "            outputs.append(out)\n",
        "        return torch.stack(outputs, dim=1)\n",
        "\n",
        "class EnhancedCrossDomainFusion(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.cross_attn1 = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.cross_attn2 = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm4 = nn.LayerNorm(hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, h_temporal, h_spectral):\n",
        "        attn_ts, _ = self.cross_attn1(self.norm1(h_temporal), self.norm2(h_spectral), h_spectral)\n",
        "        attn_st, _ = self.cross_attn2(self.norm3(h_spectral), self.norm4(h_temporal), h_temporal)\n",
        "        h_t = h_temporal + self.dropout(attn_ts)\n",
        "        h_s = h_spectral + self.dropout(attn_st)\n",
        "        pooled_t = h_t.mean(dim=1)\n",
        "        pooled_s = h_s.mean(dim=1)\n",
        "        gate_input = torch.cat([pooled_t, pooled_s], dim=-1)\n",
        "        gate_weight = self.gate(gate_input)\n",
        "        fused = gate_weight * pooled_t + (1 - gate_weight) * pooled_s\n",
        "        fused = fused + self.ffn(self.norm4(fused))\n",
        "        return fused\n",
        "\n",
        "class EnhancedTemporalEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, hidden_dim, 3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels, hidden_dim, 5, padding=2)\n",
        "        self.conv3 = nn.Conv1d(in_channels, hidden_dim, 7, padding=3)\n",
        "        self.fusion_conv = nn.Conv1d(hidden_dim * 3, hidden_dim, 1)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "        self.act = nn.GELU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = F.relu(self.conv1(x))\n",
        "        h2 = F.relu(self.conv2(x))\n",
        "        h3 = F.relu(self.conv3(x))\n",
        "        h = torch.cat([h1, h2, h3], dim=1)\n",
        "        h = self.fusion_conv(h)\n",
        "        h = h.transpose(1, 2)\n",
        "        h = self.norm(h)\n",
        "        h = self.act(h)\n",
        "        h = self.dropout(h)\n",
        "        return h\n",
        "\n",
        "class EnhancedParametricSpectralHAR(nn.Module):\n",
        "    def __init__(self, seq_len=128, in_channels=9, num_classes=6,\n",
        "                 num_basis=64, hidden_dim=128, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.spectral_operator = LearnedAdaptiveSpectralTransform(seq_len, in_channels, num_basis)\n",
        "        self.spectral_conv = nn.Sequential(\n",
        "            nn.Linear(num_basis, num_basis * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(num_basis * 2, num_basis)\n",
        "        )\n",
        "        self.spectral_attn = SpectralAttention(num_basis, num_heads, dropout)\n",
        "        self.spectral_proj = nn.Linear(num_basis, hidden_dim)\n",
        "        self.temporal_encoder = EnhancedTemporalEncoder(in_channels, hidden_dim, dropout)\n",
        "        self.fusion = EnhancedCrossDomainFusion(hidden_dim, num_heads, dropout)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        B, C, T = x.shape\n",
        "        spectral = self.spectral_operator(x)\n",
        "        spectral = self.spectral_conv(spectral)\n",
        "        spectral = self.spectral_attn(spectral)\n",
        "        spectral_pooled = spectral.mean(dim=1)\n",
        "        spectral_emb = self.spectral_proj(spectral_pooled).unsqueeze(1)\n",
        "        temporal = self.temporal_encoder(x)\n",
        "        spectral_expanded = spectral_emb.expand(B, temporal.size(1), -1)\n",
        "        fused = self.fusion(temporal, spectral_expanded)\n",
        "        logits = self.classifier(fused)\n",
        "        return logits\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        B, C, T = x.shape\n",
        "        spectral = self.spectral_operator(x)\n",
        "        spectral = self.spectral_conv(spectral)\n",
        "        spectral = self.spectral_attn(spectral)\n",
        "        spectral_pooled = spectral.mean(dim=1)\n",
        "        spectral_emb = self.spectral_proj(spectral_pooled).unsqueeze(1)\n",
        "        temporal = self.temporal_encoder(x)\n",
        "        spectral_expanded = spectral_emb.expand(B, temporal.size(1), -1)\n",
        "        fused = self.fusion(temporal, spectral_expanded)\n",
        "        return fused\n",
        "\n",
        "def plot_tsne(features, labels, activity_names, save_path, samples_per_class=600):\n",
        "    sampled_features, sampled_labels = [], []\n",
        "    for i in range(len(activity_names)):\n",
        "        class_mask = (labels == i)\n",
        "        class_indices = np.where(class_mask)[0]\n",
        "        if len(class_indices) > 0:\n",
        "            if len(class_indices) >= samples_per_class:\n",
        "                selected_indices = np.random.choice(class_indices, samples_per_class, replace=False)\n",
        "            else:\n",
        "                selected_indices = class_indices\n",
        "            sampled_features.append(features[selected_indices])\n",
        "            sampled_labels.append(labels[selected_indices])\n",
        "    features_sampled = np.vstack(sampled_features)\n",
        "    labels_sampled = np.concatenate(sampled_labels)\n",
        "    n_samples = features_sampled.shape[0]\n",
        "    perplexity = min(30, n_samples - 1)\n",
        "    features_2d = TSNE(n_components=2, perplexity=perplexity, learning_rate=200, random_state=42).fit_transform(features_sampled)\n",
        "    num_classes = len(activity_names)\n",
        "    cmap = plt.cm.get_cmap('tab20', num_classes)\n",
        "    colors = [cmap(i) for i in range(num_classes)]\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    for i, activity in enumerate(activity_names):\n",
        "        mask = (labels_sampled == i)\n",
        "        if np.any(mask):\n",
        "            plt.scatter(features_2d[mask, 0], features_2d[mask, 1],\n",
        "                       color=colors[i], marker='o', s=19, alpha=0.6, label=activity)\n",
        "    plt.legend(title=\"Activities\", fontsize=8, loc='best', ncol=2)\n",
        "    plt.xlabel(\"t-SNE Component 1\", fontsize=12)\n",
        "    plt.ylabel(\"t-SNE Component 2\", fontsize=12)\n",
        "    plt.title(\"t-SNE Visualization\", fontsize=14)\n",
        "    plt.grid(False)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(cm, activity_names, save_path):\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    num_classes = len(activity_names)\n",
        "    labels = []\n",
        "    for name in activity_names:\n",
        "        if len(name) > 15:\n",
        "            words = name.split()\n",
        "            if len(words) > 1:\n",
        "                mid = len(words) // 2\n",
        "                labels.append(' '.join(words[:mid]) + '\\n' + ' '.join(words[mid:]))\n",
        "            else:\n",
        "                labels.append(name[:15] + '\\n' + name[15:])\n",
        "        else:\n",
        "            labels.append(name)\n",
        "    df = pd.DataFrame(cm_normalized, index=labels, columns=labels)\n",
        "    annot = df.copy().astype(str)\n",
        "    for i in range(df.shape[0]):\n",
        "        for j in range(df.shape[1]):\n",
        "            v = df.iloc[i, j]\n",
        "            annot.iloc[i, j] = f\"{v:.2f}\"\n",
        "    figsize = max(8, num_classes * 0.5)\n",
        "    plt.figure(figsize=(figsize, figsize))\n",
        "    sns.heatmap(df, annot=annot.values, fmt=\"\", cmap=\"Blues\", cbar=True,\n",
        "                annot_kws={\"size\": max(6, 12 - num_classes // 3)}, vmin=0, vmax=1)\n",
        "    plt.xticks(rotation=45, ha='right', fontsize=max(6, 11 - num_classes // 4))\n",
        "    plt.yticks(rotation=0, fontsize=max(6, 11 - num_classes // 4))\n",
        "    for spine in plt.gca().spines.values():\n",
        "        spine.set_visible(True)\n",
        "        spine.set_linewidth(0.5)\n",
        "        spine.set_edgecolor('black')\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "    plt.title('Confusion Matrix', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def evaluate(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in test_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            logits = model(batch_x)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_y.cpu().numpy())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    return acc, f1, precision, recall\n",
        "\n",
        "def extract_features_and_predictions(model, data_loader, device):\n",
        "    model.eval()\n",
        "    all_features, all_preds, all_labels = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in data_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            features = model.extract_features(batch_x)\n",
        "            logits = model(batch_x)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_features.append(features.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_y.cpu().numpy())\n",
        "    return np.vstack(all_features), np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "def compute_flops_params(model, input_shape, device):\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, *input_shape).to(device)\n",
        "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
        "    flops_m = macs * 2 / 1e6\n",
        "    params_m = params / 1e6\n",
        "    return flops_m, params_m\n",
        "\n",
        "def measure_inference_time(model, input_shape, device, n_runs=100, warmup=10):\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, *input_shape).to(device)\n",
        "    with torch.no_grad():\n",
        "        for _ in range(warmup):\n",
        "            _ = model(dummy_input)\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.synchronize()\n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_runs):\n",
        "            _ = model(dummy_input)\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.synchronize()\n",
        "    end = time.time()\n",
        "    return (end - start) / n_runs * 1000\n",
        "\n",
        "def train_single_dataset(dataset_name, X_train, y_train, X_test, y_test, activity_names, device, epochs=100):\n",
        "    seq_len = X_train.shape[1]\n",
        "    input_dim = X_train.shape[2]\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    train_dataset = UCIHARDataset(X_train, y_train)\n",
        "    test_dataset = UCIHARDataset(X_test, y_test)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
        "    model = EnhancedParametricSpectralHAR(\n",
        "        seq_len=seq_len,\n",
        "        in_channels=input_dim,\n",
        "        num_classes=num_classes,\n",
        "        num_basis=64,\n",
        "        hidden_dim=128,\n",
        "        num_heads=4,\n",
        "        dropout=0.2\n",
        "    ).to(device)\n",
        "    flops_m, params_m = compute_flops_params(model, (seq_len, input_dim), device)\n",
        "    inf_time = measure_inference_time(model, (seq_len, input_dim), device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    scaler = GradScaler()\n",
        "    best_acc = 0.0\n",
        "    best_metrics = {}\n",
        "    best_model_state = None\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training {dataset_name} with Modified PSN\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Params: {params_m:.2f}M | FLOPs: {flops_m:.2f}M | Inf: {inf_time:.2f}ms\")\n",
        "    print(f\"Input: ({seq_len}, {input_dim}) | Classes: {num_classes}\")\n",
        "    print(f\"{'Epoch':<8} {'LR':<10} {'Loss':<10} {'Acc':<10} {'F1':<10} {'Prec':<10} {'Rec':<10}\")\n",
        "    print(\"-\" * 60)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                logits = model(batch_x)\n",
        "                loss = criterion(logits, batch_y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            total_loss += loss.item()\n",
        "        scheduler.step()\n",
        "        test_acc, test_f1, test_prec, test_rec = evaluate(model, test_loader, device)\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_metrics = {\n",
        "                'acc': test_acc,\n",
        "                'f1': test_f1,\n",
        "                'prec': test_prec,\n",
        "                'rec': test_rec\n",
        "            }\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            best_msg = \" (*)\"\n",
        "        else:\n",
        "            best_msg = \"\"\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"{epoch+1:<8} {current_lr:<10.6f} {total_loss/len(train_loader):<10.4f} \"\n",
        "              f\"{test_acc:<10.4f} {test_f1:<10.4f} {test_prec:<10.4f} {test_rec:<10.4f}{best_msg}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"Best - Acc: {best_metrics['acc']:.4f} | F1: {best_metrics['f1']:.4f} | Prec: {best_metrics['prec']:.4f} | Rec: {best_metrics['rec']:.4f}\")\n",
        "    print(f\"Params: {params_m:.2f}M | FLOPs: {flops_m:.2f}M | Inf: {inf_time:.2f}ms\")\n",
        "    model.load_state_dict(best_model_state)\n",
        "    features, preds, labels = extract_features_and_predictions(model, test_loader, device)\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "    tsne_path = f\"{dataset_name}_PSN_tsne.png\"\n",
        "    cm_path = f\"{dataset_name}_PSN_confusion_matrix.png\"\n",
        "    print(f\"\\nGenerating t-SNE plot for {dataset_name}...\")\n",
        "    plot_tsne(features, labels, activity_names, tsne_path)\n",
        "    print(f\"Generating Confusion Matrix for {dataset_name}...\")\n",
        "    plot_confusion_matrix(cm, activity_names, cm_path)\n",
        "    return {\n",
        "        'Dataset': dataset_name,\n",
        "        'Params(M)': round(params_m, 2),\n",
        "        'FLOPs(M)': round(flops_m, 2),\n",
        "        'Inf(ms)': round(inf_time, 2),\n",
        "        'Acc': round(best_metrics['acc'], 4),\n",
        "        'F1': round(best_metrics['f1'], 4),\n",
        "        'Prec': round(best_metrics['prec'], 4),\n",
        "        'Rec': round(best_metrics['rec'], 4)\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"=\" * 80)\n",
        "    print(\"PSN (Parametric Spectral Network) - Modified Training\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Device: {device}\\n\")\n",
        "    datasets_config = [\n",
        "        ('UCI-HAR', load_uci_har, '/content/drive/MyDrive/HAR_Dataset/UCI'),\n",
        "    ]\n",
        "    all_datasets = {}\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Loading UCI-HAR Dataset\")\n",
        "    print(\"=\" * 80)\n",
        "    for dataset_name, loader_func, data_path in datasets_config:\n",
        "        try:\n",
        "            print(f\"\\n{'#'*60}\")\n",
        "            print(f\"Loading {dataset_name}...\")\n",
        "            print(f\"{'#'*60}\")\n",
        "            data = loader_func(data_path)\n",
        "            if data is None or data[0] is None:\n",
        "                print(f\"Failed to load {dataset_name}\")\n",
        "                continue\n",
        "            X_train, y_train, X_test, y_test, activity_names = data\n",
        "            num_train_classes = len(np.unique(y_train))\n",
        "            num_test_classes = len(np.unique(y_test))\n",
        "            print(f\"Train: {X_train.shape} | Classes: {num_train_classes}\")\n",
        "            print(f\"Test: {X_test.shape} | Classes: {num_test_classes}\")\n",
        "            print(f\"Activity Names: {activity_names}\")\n",
        "            train_class_dist = Counter(y_train)\n",
        "            test_class_dist = Counter(y_test)\n",
        "            print(f\"Train class distribution: {dict(sorted(train_class_dist.items()))}\")\n",
        "            print(f\"Test class distribution: {dict(sorted(test_class_dist.items()))}\")\n",
        "            all_datasets[dataset_name] = {\n",
        "                'X_train': X_train,\n",
        "                'y_train': y_train,\n",
        "                'X_test': X_test,\n",
        "                'y_test': y_test,\n",
        "                'activity_names': activity_names\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {dataset_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Successfully loaded {len(all_datasets)} datasets\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "    results = []\n",
        "    for dataset_name, dataset_data in all_datasets.items():\n",
        "        try:\n",
        "            result = train_single_dataset(\n",
        "                dataset_name,\n",
        "                dataset_data['X_train'],\n",
        "                dataset_data['y_train'],\n",
        "                dataset_data['X_test'],\n",
        "                dataset_data['y_test'],\n",
        "                dataset_data['activity_names'],\n",
        "                device,\n",
        "                epochs=100\n",
        "            )\n",
        "            results.append(result)\n",
        "        except Exception as e:\n",
        "            print(f\"Error training {dataset_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    if results:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"FINAL RESULTS\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "        results_df = pd.DataFrame(results)\n",
        "        results_df = results_df[['Dataset', 'Params(M)', 'FLOPs(M)', 'Inf(ms)', 'Acc', 'F1', 'Prec', 'Rec']]\n",
        "        print(results_df.to_string(index=False))\n",
        "        print(f\"\\n{'='*80}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w4KlwTRfZsDR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}