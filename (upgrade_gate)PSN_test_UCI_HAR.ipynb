{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRU2lkv-Ya_1",
        "outputId": "7a98a746-84ec-458f-c3c8-873d8003bf02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.12/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: ptflops in /usr/local/lib/python3.12/dist-packages (0.7.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->thop) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->thop) (3.0.3)\n",
            "================================================================================\n",
            "Improved PSN (Parametric Spectral Network) Multi-Dataset Training\n",
            "with Ablation Study and Frequency Learning Visualization\n",
            "================================================================================\n",
            "Device: cuda\n",
            "\n",
            "Hyperparameters:\n",
            "  Frequency LR: 0.0001\n",
            "  Other LR: 0.001\n",
            "  Epochs: 50\n",
            "================================================================================\n",
            "Loading All Datasets\n",
            "================================================================================\n",
            "\n",
            "############################################################\n",
            "Loading UCI-HAR...\n",
            "############################################################\n",
            "Train: (7352, 128, 9) | Classes: 6\n",
            "Test: (2947, 128, 9) | Classes: 6\n",
            "Activity Names: ['Walking', 'Walking Upstairs', 'Walking Downstairs', 'Sitting', 'Standing', 'Laying']\n",
            "Train class distribution: {np.int64(0): 1226, np.int64(1): 1073, np.int64(2): 986, np.int64(3): 1286, np.int64(4): 1374, np.int64(5): 1407}\n",
            "Test class distribution: {np.int64(0): 496, np.int64(1): 471, np.int64(2): 420, np.int64(3): 491, np.int64(4): 532, np.int64(5): 537}\n",
            "\n",
            "================================================================================\n",
            "Successfully loaded 1 datasets\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ABLATION STUDY - UCI-HAR\n",
            "Frequency LR: 0.0001, Other LR: 0.001\n",
            "================================================================================\n",
            "\n",
            "--- Full Model ---\n",
            "  Acc: 0.9199 | F1: 0.9203 | Params: 2.54M | FLOPs: 65.84M | Inf: 3.73ms | Delta: -\n",
            "\n",
            "--- FFT Baseline ---\n",
            "  Acc: 0.9498 | F1: 0.9491 | Params: 0.44M | FLOPs: 56.41M | Inf: 1.47ms | Delta: 3.0%\n",
            "\n",
            "--- w/o Spectral Path ---\n",
            "  Acc: 0.9335 | F1: 0.9340 | Params: 0.25M | FLOPs: 56.04M | Inf: 1.25ms | Delta: 1.4%\n",
            "\n",
            "--- w/o Temporal Path ---\n",
            "  Acc: 0.9091 | F1: 0.9074 | Params: 0.12M | FLOPs: 1.28M | Inf: 0.91ms | Delta: -1.1%\n",
            "\n",
            "--- w/o Hamming Window ---\n",
            "  Acc: 0.9440 | F1: 0.9443 | Params: 2.54M | FLOPs: 65.84M | Inf: 3.49ms | Delta: 2.4%\n",
            "\n",
            "--- Magnitude Only ---\n",
            "  Acc: 0.9342 | F1: 0.9343 | Params: 1.44M | FLOPs: 62.86M | Inf: 3.03ms | Delta: 1.4%\n",
            "\n",
            "--- Standard Conv ---\n",
            "  Acc: 0.9406 | F1: 0.9397 | Params: 2.55M | FLOPs: 69.35M | Inf: 2.91ms | Delta: 2.1%\n",
            "\n",
            "--- Attention Fusion ---\n",
            "Error processing UCI-HAR: 'ImprovedFusion' object has no attribute 'norm'\n",
            "\n",
            "################################################################################\n",
            "################################################################################\n",
            "FINAL SUMMARY - ALL RESULTS\n",
            "################################################################################\n",
            "################################################################################\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ALL EXPERIMENTS COMPLETED!\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3147897226.py\", line 1557, in <cell line: 0>\n",
            "    ablation_results, full_model_state = run_ablation_study(\n",
            "                                         ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3147897226.py\", line 1428, in run_ablation_study\n",
            "    flops_m, params_m = compute_flops_params(model, (seq_len, input_dim), device)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3147897226.py\", line 1034, in compute_flops_params\n",
            "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/thop/profile.py\", line 212, in profile\n",
            "    model(*inputs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3147897226.py\", line 826, in forward\n",
            "    fused = self.fusion.norm(fused)\n",
            "            ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1964, in __getattr__\n",
            "    raise AttributeError(\n",
            "AttributeError: 'ImprovedFusion' object has no attribute 'norm'. Did you mean: 'norm1'?\n"
          ]
        }
      ],
      "source": [
        "!pip install thop ptflops\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from thop import profile\n",
        "from collections import Counter\n",
        "from glob import glob\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "\n",
        "def clean_state_dict(state_dict):\n",
        "    return {k: v for k, v in state_dict.items()\n",
        "            if 'total_ops' not in k and 'total_params' not in k}\n",
        "\n",
        "class UCIHARDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = torch.FloatTensor(data)\n",
        "        self.labels = torch.LongTensor(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "def read_txt_matrix(file_path):\n",
        "    return np.loadtxt(file_path)\n",
        "\n",
        "\n",
        "def load_uci_har(root_path='/content/drive/MyDrive/HAR_Dataset/UCI'):\n",
        "    UCI_CHANNELS_PREFIX = [\n",
        "        \"total_acc_x_\", \"total_acc_y_\", \"total_acc_z_\",\n",
        "        \"body_acc_x_\", \"body_acc_y_\", \"body_acc_z_\",\n",
        "        \"body_gyro_x_\", \"body_gyro_y_\", \"body_gyro_z_\",\n",
        "    ]\n",
        "    def load_split(split):\n",
        "        channels = []\n",
        "        for prefix in UCI_CHANNELS_PREFIX:\n",
        "            file_path = os.path.join(root_path, f\"{prefix}{split}.txt\")\n",
        "            if not os.path.exists(file_path):\n",
        "                raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "            channels.append(read_txt_matrix(file_path))\n",
        "        X = np.stack(channels, axis=1)\n",
        "        y = read_txt_matrix(os.path.join(root_path, f\"y_{split}.txt\")).astype(int) - 1\n",
        "        return X, y\n",
        "    X_train, y_train = load_split('train')\n",
        "    X_test, y_test = load_split('test')\n",
        "    X_train = X_train.transpose(0, 2, 1)\n",
        "    X_test = X_test.transpose(0, 2, 1)\n",
        "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train_flat)\n",
        "    X_train_flat = scaler.transform(X_train_flat)\n",
        "    X_test_flat = scaler.transform(X_test_flat)\n",
        "    X_train = X_train_flat.reshape(X_train.shape)\n",
        "    X_test = X_test_flat.reshape(X_test.shape)\n",
        "    activity_names = ['Walking', 'Walking Upstairs', 'Walking Downstairs', 'Sitting', 'Standing', 'Laying']\n",
        "    return X_train, y_train.astype(np.int64), X_test, y_test.astype(np.int64), activity_names\n",
        "\n",
        "\n",
        "def load_wisdm_data(dataset_path=\"/content/drive/MyDrive/HAR_Dataset/WISDM\"):\n",
        "    if os.path.isfile(dataset_path):\n",
        "        file_paths = [dataset_path]\n",
        "    else:\n",
        "        possible_files = ['WISDM_ar_v1.1_raw.txt', 'WISDM_ar_v1.1_trans.arff', 'wisdm-dataset.txt', 'actitracker_raw.txt']\n",
        "        file_paths = []\n",
        "        for filename in possible_files:\n",
        "            full_path = os.path.join(dataset_path, filename)\n",
        "            if os.path.exists(full_path):\n",
        "                file_paths.append(full_path)\n",
        "    if not file_paths:\n",
        "        return None, None, None, None, None\n",
        "    all_data = []\n",
        "    for file_path in file_paths:\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        cleaned_data = []\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            line = line.rstrip(';').rstrip(',')\n",
        "            if ',' in line:\n",
        "                parts = line.split(',')\n",
        "            elif ';' in line:\n",
        "                parts = line.split(';')\n",
        "            else:\n",
        "                continue\n",
        "            if len(parts) < 6:\n",
        "                continue\n",
        "            try:\n",
        "                user = parts[0].strip()\n",
        "                activity = parts[1].strip()\n",
        "                timestamp = parts[2].strip()\n",
        "                x_str = parts[3].strip()\n",
        "                y_str = parts[4].strip()\n",
        "                z_str = parts[5].strip()\n",
        "                if ';' in x_str:\n",
        "                    x_str = x_str.split(';')[0]\n",
        "                if ';' in y_str:\n",
        "                    y_str = y_str.split(';')[0]\n",
        "                if ';' in z_str:\n",
        "                    z_str = z_str.split(';')[0]\n",
        "                x = float(x_str)\n",
        "                y = float(y_str)\n",
        "                z = float(z_str)\n",
        "                cleaned_data.append([user, activity, timestamp, x, y, z])\n",
        "            except (ValueError, IndexError):\n",
        "                continue\n",
        "        if cleaned_data:\n",
        "            df = pd.DataFrame(cleaned_data, columns=['user', 'activity', 'timestamp', 'x', 'y', 'z'])\n",
        "            df['x'] = pd.to_numeric(df['x'], errors='coerce')\n",
        "            df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
        "            df['z'] = pd.to_numeric(df['z'], errors='coerce')\n",
        "            df = df.dropna()\n",
        "            all_data.append(df)\n",
        "    if not all_data:\n",
        "        return None, None, None, None, None\n",
        "    combined_df = pd.concat(all_data, ignore_index=True)\n",
        "    combined_df = combined_df.dropna()\n",
        "    combined_df = combined_df[combined_df['activity'].str.strip() != '']\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    groups = combined_df.groupby(['user', 'activity']) if 'user' in combined_df.columns else combined_df.groupby(['activity'])\n",
        "    window_size = 80\n",
        "    step = 40\n",
        "    for group_name, group_data in groups:\n",
        "        activity = group_name[-1] if isinstance(group_name, tuple) else group_name\n",
        "        acc_data = group_data[['x', 'y', 'z']].values.astype(np.float32)\n",
        "        if len(acc_data) < window_size:\n",
        "            continue\n",
        "        start = 0\n",
        "        while start + window_size <= len(acc_data):\n",
        "            window_data = acc_data[start:start + window_size, :]\n",
        "            all_windows.append(window_data)\n",
        "            all_labels.append(activity)\n",
        "            start += step\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    scaler = StandardScaler()\n",
        "    X_windowed_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_windowed_flat = scaler.fit_transform(X_windowed_flat)\n",
        "    X_windowed = X_windowed_flat.reshape(X_windowed.shape)\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(all_labels)\n",
        "    class_names = [str(label) for label in label_encoder.classes_]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    return X_train, y_train, X_test, y_test, class_names\n",
        "\n",
        "\n",
        "def load_dsads_data(data_path, w_s=25, stride=12):\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    activities = {\n",
        "        'a01': 'sitting', 'a02': 'standing', 'a03': 'lying on back',\n",
        "        'a04': 'lying on right side', 'a05': 'ascending stairs',\n",
        "        'a06': 'descending stairs', 'a07': 'standing in an elevator still',\n",
        "        'a08': 'moving around in an elevator', 'a09': 'walking in a parking lot',\n",
        "        'a10': 'walking on a treadmill with a speed of 4 kmh',\n",
        "        'a11': 'walking in flat and 15 deg inclined positions',\n",
        "        'a12': 'running on a treadmill with a speed of 8 kmh',\n",
        "        'a13': 'exercising on a stepper', 'a14': 'exercising on a cross trainer',\n",
        "        'a15': 'cycling on an exercise bike in horizontal positions',\n",
        "        'a16': 'cycling on an exercise bike in vertical positions',\n",
        "        'a17': 'rowing', 'a18': 'jumping', 'a19': 'playing basketball'\n",
        "    }\n",
        "    activity_codes = sorted(activities.keys())\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(activity_codes)\n",
        "    persons = ['p' + str(i) for i in range(1, 9)]\n",
        "    for person_str in persons:\n",
        "        for activity_str in activity_codes:\n",
        "            activity_label = label_encoder.transform([activity_str])[0]\n",
        "            pattern = os.path.join(data_path, activity_str, person_str, 's*.txt')\n",
        "            segment_files = sorted(glob(pattern))\n",
        "            if not segment_files:\n",
        "                continue\n",
        "            for f in segment_files[:11]:\n",
        "                try:\n",
        "                    segment_data = np.loadtxt(f, delimiter=',')\n",
        "                    if segment_data.shape[0] < w_s or segment_data.shape[1] < 45:\n",
        "                        continue\n",
        "                    segment_data = np.nan_to_num(segment_data, nan=0.0)\n",
        "                    start = 0\n",
        "                    while start + w_s <= segment_data.shape[0]:\n",
        "                        window_data = segment_data[start : start + w_s, :]\n",
        "                        all_windows.append(window_data)\n",
        "                        all_labels.append(activity_label)\n",
        "                        start += stride\n",
        "                except:\n",
        "                    continue\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    y_encoded = np.array(all_labels, dtype=int)\n",
        "    scaler = StandardScaler()\n",
        "    X_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_flat = scaler.fit_transform(X_flat)\n",
        "    X_windowed = X_flat.reshape(X_windowed.shape)\n",
        "    activity_names_sorted = [activities[code] for code in label_encoder.classes_]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    return X_train, y_train, X_test, y_test, activity_names_sorted\n",
        "\n",
        "\n",
        "def load_pamap2_data(dataset_dir=\"/content/drive/MyDrive/HAR_Dataset/PAMAP2\"):\n",
        "    file_paths = sorted(glob(os.path.join(dataset_dir, 'Protocol', 'subject*.dat')))\n",
        "    optional_path = os.path.join(dataset_dir, 'Optional')\n",
        "    if os.path.exists(optional_path):\n",
        "        file_paths += sorted(glob(os.path.join(optional_path, 'subject*.dat')))\n",
        "    if not file_paths:\n",
        "        return None, None, None, None, None\n",
        "    activity_labels = [\n",
        "        \"lying\", \"sitting\", \"standing\", \"walking\", \"running\", \"cycling\",\n",
        "        \"Nordic walking\", \"ascending stairs\", \"descending stairs\",\n",
        "        \"vacuum cleaning\", \"ironing\", \"rope jumping\"\n",
        "    ]\n",
        "    label_to_activity_idx = {\n",
        "        1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 12: 7, 13: 8, 16: 9, 17: 10, 24: 11\n",
        "    }\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    window_size = 100\n",
        "    step = 50\n",
        "    for file_path in file_paths:\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=r'\\s+', header=None, na_values='NaN')\n",
        "        except:\n",
        "            continue\n",
        "        df_cleaned = df.ffill().bfill()\n",
        "        if df_cleaned.empty:\n",
        "            continue\n",
        "        labels = df_cleaned.iloc[:, 1].values.astype(int)\n",
        "        all_sensor_cols = list(range(4, 10)) + list(range(21, 27)) + list(range(38, 44))\n",
        "        if df_cleaned.shape[1] < max(all_sensor_cols) + 1:\n",
        "            continue\n",
        "        features = df_cleaned.iloc[:, all_sensor_cols].values.astype(np.float32)\n",
        "        valid_indices = np.where(np.isin(labels, list(label_to_activity_idx.keys())))[0]\n",
        "        if len(valid_indices) == 0:\n",
        "            continue\n",
        "        features = features[valid_indices, :]\n",
        "        labels = labels[valid_indices]\n",
        "        if len(features) < window_size:\n",
        "            continue\n",
        "        start = 0\n",
        "        while start + window_size <= len(features):\n",
        "            window_data = features[start : start + window_size, :]\n",
        "            window_labels_raw = labels[start : start + window_size]\n",
        "            most_common_label = Counter(window_labels_raw).most_common(1)[0][0]\n",
        "            if most_common_label in label_to_activity_idx:\n",
        "                all_windows.append(window_data)\n",
        "                all_labels.append(label_to_activity_idx[most_common_label])\n",
        "            start += step\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    y_encoded = np.array(all_labels, dtype=int)\n",
        "    scaler = StandardScaler()\n",
        "    X_windowed_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_windowed_flat = scaler.fit_transform(X_windowed_flat)\n",
        "    X_windowed = X_windowed_flat.reshape(X_windowed.shape)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    return X_train, y_train, X_test, y_test, activity_labels\n",
        "\n",
        "\n",
        "def load_mhealth_data(dataset_dir=\"/content/drive/MyDrive/HAR_Dataset/MHEALTH\"):\n",
        "    if not os.path.exists(dataset_dir):\n",
        "        return None, None, None, None, None\n",
        "    subject_files = sorted([\n",
        "        os.path.join(dataset_dir, f)\n",
        "        for f in os.listdir(dataset_dir)\n",
        "        if f.startswith(\"mHealth_subject\") and f.endswith(\".log\")\n",
        "    ])\n",
        "    if not subject_files:\n",
        "        return None, None, None, None, None\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    window_size = 50\n",
        "    step = 25\n",
        "    for file_path in subject_files:\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=r'\\s+', header=None, engine='python', dtype=np.float32)\n",
        "            df = df.ffill().bfill()\n",
        "            if df.shape[1] < 24:\n",
        "                continue\n",
        "            labels = df.iloc[:, 23].values.astype(int)\n",
        "            imu_cols = [0, 1, 2] + list(range(5, 23))\n",
        "            features = df.iloc[:, imu_cols].values\n",
        "            valid_indices = np.where(labels != 0)[0]\n",
        "            if len(valid_indices) == 0:\n",
        "                continue\n",
        "            features = features[valid_indices, :]\n",
        "            labels = labels[valid_indices]\n",
        "            if len(features) < window_size:\n",
        "                continue\n",
        "            start = 0\n",
        "            while start + window_size <= len(features):\n",
        "                window_data = features[start : start + window_size, :]\n",
        "                window_labels_raw = labels[start : start + window_size]\n",
        "                most_common_label = Counter(window_labels_raw).most_common(1)[0][0]\n",
        "                all_windows.append(window_data)\n",
        "                all_labels.append(most_common_label)\n",
        "                start += step\n",
        "        except:\n",
        "            continue\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(all_labels)\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    scaler = StandardScaler()\n",
        "    X_windowed_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_windowed_flat = scaler.fit_transform(X_windowed_flat)\n",
        "    X_windowed = X_windowed_flat.reshape(X_windowed.shape)\n",
        "    mhealth_activity_mapping = {\n",
        "        1: 'Standing still', 2: 'Sitting and relaxing', 3: 'Lying down', 4: 'Walking',\n",
        "        5: 'Climbing stairs', 6: 'Waist bends forward', 7: 'Frontal elevation of arms',\n",
        "        8: 'Knees bending', 9: 'Cycling', 10: 'Jogging', 11: 'Running', 12: 'Jump front & back'\n",
        "    }\n",
        "    activity_labels = []\n",
        "    class_names = list(label_encoder.classes_)\n",
        "    for encoded_idx in range(len(class_names)):\n",
        "        original_label = class_names[encoded_idx]\n",
        "        activity_labels.append(mhealth_activity_mapping.get(original_label, f\"Unknown_Activity_{original_label}\"))\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    return X_train, y_train, X_test, y_test, activity_labels\n",
        "\n",
        "\n",
        "class MotionSenseLoader:\n",
        "    def __init__(self, frame_len, feature_name, N_classes):\n",
        "        self.feature_names = feature_name\n",
        "        self.N_Feature = len(feature_name)\n",
        "        self.frame_length = frame_len\n",
        "        self.hop_size = frame_len//2\n",
        "        self.N_classes = N_classes\n",
        "        self.label_encoder = OneHotEncoder(sparse_output=False)\n",
        "    def framing(self, signal):\n",
        "        shape = ((signal.shape[0] - self.frame_length) // self.hop_size + 1, self.frame_length)\n",
        "        strides = (signal.strides[0] * self.hop_size, signal.strides[0])\n",
        "        return np.lib.stride_tricks.as_strided(signal, shape=shape, strides=strides)\n",
        "    def create_label(self, label): return self.label_encoder.fit_transform(label)\n",
        "    def load_trainings_data(self, files, label_frame):\n",
        "        label = self.create_label(label_frame)\n",
        "        self.trainings_data, self.trainings_label = self.load_data(files, label)\n",
        "    def load_validation_data(self, files, label_frame):\n",
        "        label = self.label_encoder.transform(label_frame)\n",
        "        self.validation_data, self.validation_label = self.load_data(files, label)\n",
        "    def load_data(self, files, label):\n",
        "        feature_matrix, label_matrix = None, None\n",
        "        for i in range(len(files)):\n",
        "            try: tmp_data = pd.read_csv(files[i], engine='python')\n",
        "            except: continue\n",
        "            N_Blocks = 1+(np.shape(tmp_data)[0]-self.frame_length)//self.hop_size\n",
        "            if N_Blocks <= 0: continue\n",
        "            tmp_feature_mat = np.zeros((N_Blocks, self.frame_length, self.N_Feature))\n",
        "            tmp_label_vec = np.zeros((N_Blocks, self.N_classes))\n",
        "            for j in range(N_Blocks): tmp_label_vec[j, :] = label[i, :]\n",
        "            for idf, feat in enumerate(self.feature_names):\n",
        "                frame_matrix = self.framing(tmp_data[feat].to_numpy())\n",
        "                tmp_feature_mat[:, :, idf] = frame_matrix[:N_Blocks]\n",
        "            if feature_matrix is None:\n",
        "                feature_matrix = tmp_feature_mat\n",
        "                label_matrix = tmp_label_vec\n",
        "            else:\n",
        "                feature_matrix = np.append(feature_matrix, tmp_feature_mat, axis=0)\n",
        "                label_matrix = np.append(label_matrix, tmp_label_vec, axis=0)\n",
        "        return feature_matrix, label_matrix\n",
        "\n",
        "def load_motionsense_data(root_path='/content/drive/MyDrive/HAR_Dataset/MOTIONSENSE'):\n",
        "    files, label = [], []\n",
        "    for dirname, _, filenames in os.walk(root_path):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith('.csv') and not filename.startswith('.'):\n",
        "                full_path = os.path.join(dirname, filename)\n",
        "                if 'sub_' in filename:\n",
        "                    files.append(full_path)\n",
        "                    parent_dir = os.path.basename(os.path.dirname(full_path))\n",
        "                    if '_' in parent_dir: label.append(parent_dir.split('_')[0])\n",
        "                    else: files.pop()\n",
        "    if not files: return None, None, None, None, None\n",
        "    label_frame = pd.DataFrame(label, columns=['act'])\n",
        "    files_train, files_valid, y_train_raw, y_valid_raw = train_test_split(files, label_frame, test_size=0.2, random_state=0)\n",
        "    Feature = ['attitude.roll','attitude.pitch','attitude.yaw','gravity.x','gravity.y','gravity.z',\n",
        "               'rotationRate.x','rotationRate.y','rotationRate.z','userAcceleration.x','userAcceleration.y','userAcceleration.z']\n",
        "    N_classes = 6\n",
        "    loader = MotionSenseLoader(128, Feature, N_classes)\n",
        "    loader.load_trainings_data(files_train, y_train_raw)\n",
        "    loader.load_validation_data(files_valid, y_valid_raw)\n",
        "    X_train = loader.trainings_data.astype(np.float32).transpose(0, 2, 1)\n",
        "    X_test = loader.validation_data.astype(np.float32).transpose(0, 2, 1)\n",
        "    y_train = np.argmax(loader.trainings_label, axis=1)\n",
        "    y_test = np.argmax(loader.validation_label, axis=1)\n",
        "    activity_names = list(loader.label_encoder.categories_[0])\n",
        "    return X_train, y_train, X_test, y_test, activity_names\n",
        "\n",
        "\n",
        "def load_unimib_shar_data(dataset_dir=\"/content/drive/MyDrive/HAR_Dataset/UNIMIB\"):\n",
        "    train_path = os.path.join(dataset_dir, \"unimib_train.csv\")\n",
        "    test_path = os.path.join(dataset_dir, \"unimib_test.csv\")\n",
        "    val_path = os.path.join(dataset_dir, \"unimib_val.csv\")\n",
        "    if not os.path.exists(train_path): return None, None, None, None, None\n",
        "    def process_unimib_csv(path):\n",
        "        if not os.path.exists(path): return np.array([]), np.array([])\n",
        "        df = pd.read_csv(path)\n",
        "        df = df.sort_values(by=['ID', 't'])\n",
        "        X_list, y_list = [], []\n",
        "        for _, group in df.groupby('ID'):\n",
        "            X_list.append(group[['ax', 'ay', 'az']].values.astype(np.float32))\n",
        "            y_list.append(group['label'].iloc[0])\n",
        "        return np.array(X_list), np.array(y_list)\n",
        "    X_train, y_train_raw = process_unimib_csv(train_path)\n",
        "    X_test, y_test_raw = process_unimib_csv(test_path)\n",
        "    if os.path.exists(val_path):\n",
        "        X_val, y_val_raw = process_unimib_csv(val_path)\n",
        "        if len(X_val) > 0:\n",
        "            X_test = np.concatenate((X_test, X_val), axis=0)\n",
        "            y_test_raw = np.concatenate((y_test_raw, y_val_raw), axis=0)\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train_raw)\n",
        "    y_test = le.transform(y_test_raw)\n",
        "    class_names = [str(c) for c in le.classes_]\n",
        "    B_train, T, C = X_train.shape\n",
        "    B_test, _, _ = X_test.shape\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train.reshape(B_train, -1)).reshape(B_train, T, C).transpose(0, 2, 1)\n",
        "    X_test = scaler.transform(X_test.reshape(B_test, -1)).reshape(B_test, T, C).transpose(0, 2, 1)\n",
        "    return X_train, y_train, X_test, y_test, class_names\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1.0, gamma=2.0, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=4):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_channels, in_channels // reduction, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_channels // reduction, in_channels, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, t = x.size()\n",
        "        avg_out = self.fc(self.avg_pool(x).view(b, c))\n",
        "        max_out = self.fc(self.max_pool(x).view(b, c))\n",
        "        out = self.sigmoid(avg_out + max_out).view(b, c, 1)\n",
        "        return x * out\n",
        "\n",
        "\n",
        "class AttentionPooling(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_weights = self.attention(x)\n",
        "        attn_weights = F.softmax(attn_weights, dim=1)\n",
        "        weighted = x * attn_weights\n",
        "        pooled = weighted.sum(dim=1)\n",
        "        return pooled, attn_weights\n",
        "\n",
        "\n",
        "class LearnableTimeVaryingSpectral(nn.Module):\n",
        "    def __init__(self, spectral_dim, seq_len, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.time_proj = nn.Linear(spectral_dim, seq_len * hidden_dim)\n",
        "\n",
        "    def forward(self, spectral_pooled):\n",
        "        B = spectral_pooled.size(0)\n",
        "        time_varying = self.time_proj(spectral_pooled)\n",
        "        time_varying = time_varying.reshape(B, self.seq_len, -1)\n",
        "        return time_varying\n",
        "\n",
        "\n",
        "class ImprovedSpectralOperator(nn.Module):\n",
        "    def __init__(self, seq_len, in_channels, num_basis=64, use_hamming=True, use_real_imag=True):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.in_channels = in_channels\n",
        "        self.num_basis = num_basis\n",
        "        self.use_hamming = use_hamming\n",
        "        self.use_real_imag = use_real_imag\n",
        "\n",
        "        self.register_buffer('t', torch.arange(seq_len).float())\n",
        "\n",
        "        if use_hamming:\n",
        "            hamming_window = torch.hamming_window(seq_len)\n",
        "            self.register_buffer('hamming_window', hamming_window)\n",
        "\n",
        "        low_band = num_basis // 3\n",
        "        mid_band = num_basis // 3\n",
        "        high_band = num_basis - low_band - mid_band\n",
        "        freqs_low = torch.linspace(0, seq_len//8, low_band) / seq_len\n",
        "        freqs_mid = torch.linspace(seq_len//8, seq_len//4, mid_band) / seq_len\n",
        "        freqs_high = torch.linspace(seq_len//4, seq_len//2, high_band) / seq_len\n",
        "        init_freqs = torch.cat([freqs_low, freqs_mid, freqs_high])\n",
        "        init_freqs_logit = torch.logit(init_freqs * 2)\n",
        "        self.frequencies_logit = nn.Parameter(init_freqs_logit)\n",
        "\n",
        "        self.phases = nn.Parameter(torch.zeros(num_basis))\n",
        "        self.channel_weights_real = nn.Parameter(torch.randn(in_channels, num_basis) * 0.02)\n",
        "        self.channel_weights_imag = nn.Parameter(torch.randn(in_channels, num_basis) * 0.02)\n",
        "        self.gamma = nn.Parameter(torch.ones(in_channels, 1))\n",
        "        self.beta = nn.Parameter(torch.zeros(in_channels, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, T = x.shape\n",
        "\n",
        "        if self.use_hamming:\n",
        "            x = x * self.hamming_window.unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        frequencies = torch.sigmoid(self.frequencies_logit) * 0.5\n",
        "\n",
        "        args = 2 * np.pi * frequencies.unsqueeze(1) * self.t.unsqueeze(0) + self.phases.unsqueeze(1)\n",
        "        basis_real = torch.cos(args)\n",
        "        basis_imag = -torch.sin(args)\n",
        "\n",
        "        spectral_real = torch.einsum('bct,ft->bcf', x, basis_real)\n",
        "        spectral_imag = torch.einsum('bct,ft->bcf', x, basis_imag)\n",
        "\n",
        "        weighted_real = spectral_real * (1 + self.channel_weights_real.unsqueeze(0)) - \\\n",
        "                       spectral_imag * self.channel_weights_imag.unsqueeze(0)\n",
        "        weighted_imag = spectral_real * self.channel_weights_imag.unsqueeze(0) + \\\n",
        "                       spectral_imag * (1 + self.channel_weights_real.unsqueeze(0))\n",
        "\n",
        "        if self.use_real_imag:\n",
        "            spectral_features = torch.cat([weighted_real, weighted_imag], dim=-1)\n",
        "            spectral_features = spectral_features / math.sqrt(self.seq_len)\n",
        "            gamma_expanded = self.gamma.unsqueeze(0).expand(B, C, self.num_basis * 2)\n",
        "            beta_expanded = self.beta.unsqueeze(0).expand(B, C, self.num_basis * 2)\n",
        "            spectral_features = spectral_features * gamma_expanded + beta_expanded\n",
        "        else:\n",
        "            spectral_mag = torch.sqrt(weighted_real**2 + weighted_imag**2 + 1e-8)\n",
        "            spectral_features = spectral_mag / math.sqrt(self.seq_len)\n",
        "            spectral_features = spectral_features * self.gamma.unsqueeze(0) + self.beta.unsqueeze(0)\n",
        "\n",
        "        return spectral_features\n",
        "\n",
        "\n",
        "class DepthwiseSeparableConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, padding=0):\n",
        "        super().__init__()\n",
        "        self.depthwise = nn.Conv1d(in_channels, in_channels, kernel_size, padding=padding, groups=in_channels)\n",
        "        self.pointwise = nn.Conv1d(in_channels, out_channels, 1)\n",
        "        self.bn = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GatedMechanism(nn.Module):\n",
        "    def __init__(self, hidden_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.gate_linear = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.value_linear = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = torch.sigmoid(self.gate_linear(x))\n",
        "        value = torch.tanh(self.value_linear(x))\n",
        "        out = gate * value\n",
        "        out = self.dropout(out)\n",
        "        out = out + x\n",
        "        out = self.norm(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ImprovedTemporalEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dim, use_depthwise=True, use_gated=True, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.use_gated = use_gated\n",
        "\n",
        "        if use_depthwise:\n",
        "            self.conv1 = DepthwiseSeparableConv1d(in_channels, hidden_dim, 3, padding=1)\n",
        "            self.conv2 = DepthwiseSeparableConv1d(in_channels, hidden_dim, 5, padding=2)\n",
        "            self.conv3 = DepthwiseSeparableConv1d(in_channels, hidden_dim, 7, padding=3)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv1d(in_channels, hidden_dim, 3, padding=1)\n",
        "            self.conv2 = nn.Conv1d(in_channels, hidden_dim, 5, padding=2)\n",
        "            self.conv3 = nn.Conv1d(in_channels, hidden_dim, 7, padding=3)\n",
        "            self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
        "            self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
        "            self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
        "\n",
        "        self.fusion_conv = nn.Conv1d(hidden_dim * 3, hidden_dim, 1)\n",
        "\n",
        "        if use_gated:\n",
        "            self.gated = GatedMechanism(hidden_dim, dropout)\n",
        "        else:\n",
        "            self.attn = nn.MultiheadAttention(hidden_dim, 1, dropout=dropout, batch_first=True)\n",
        "            self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "            self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 4, hidden_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.use_depthwise = use_depthwise\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_depthwise:\n",
        "            h1 = F.relu(self.conv1(x))\n",
        "            h2 = F.relu(self.conv2(x))\n",
        "            h3 = F.relu(self.conv3(x))\n",
        "        else:\n",
        "            h1 = F.relu(self.bn1(self.conv1(x)))\n",
        "            h2 = F.relu(self.bn2(self.conv2(x)))\n",
        "            h3 = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "        h = torch.cat([h1, h2, h3], dim=1)\n",
        "        h = self.fusion_conv(h)\n",
        "        h = h.transpose(1, 2)\n",
        "\n",
        "        if self.use_gated:\n",
        "            h = self.gated(h)\n",
        "        else:\n",
        "            h_norm = self.norm1(h)\n",
        "            attn_out, _ = self.attn(h_norm, h_norm, h_norm)\n",
        "            h = h + self.dropout(attn_out)\n",
        "            h = self.norm2(h)\n",
        "\n",
        "        h = h + self.ffn(h)\n",
        "        return h\n",
        "\n",
        "\n",
        "class ImprovedFusion(nn.Module):\n",
        "    def __init__(self, hidden_dim, use_gated=True, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.use_gated = use_gated\n",
        "\n",
        "        if use_gated:\n",
        "            self.gate = nn.Sequential(\n",
        "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "                nn.Sigmoid()\n",
        "            )\n",
        "            self.ffn = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "                nn.Dropout(dropout)\n",
        "            )\n",
        "            self.norm = nn.LayerNorm(hidden_dim)\n",
        "        else:\n",
        "            self.cross_attn1 = nn.MultiheadAttention(hidden_dim, 1, dropout=dropout, batch_first=True)\n",
        "            self.cross_attn2 = nn.MultiheadAttention(hidden_dim, 1, dropout=dropout, batch_first=True)\n",
        "            self.gate = nn.Sequential(\n",
        "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "                nn.Sigmoid()\n",
        "            )\n",
        "            self.ffn = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, hidden_dim * 4),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(hidden_dim * 4, hidden_dim),\n",
        "                nn.Dropout(dropout)\n",
        "            )\n",
        "            self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "            self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "            self.norm3 = nn.LayerNorm(hidden_dim)\n",
        "            self.norm4 = nn.LayerNorm(hidden_dim)\n",
        "            self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, h_temporal, h_spectral):\n",
        "        if self.use_gated:\n",
        "            pooled_t = h_temporal.mean(dim=1)\n",
        "            pooled_s = h_spectral.mean(dim=1)\n",
        "            gate_input = torch.cat([pooled_t, pooled_s], dim=-1)\n",
        "            gate_weight = self.gate(gate_input)\n",
        "            fused = gate_weight * pooled_t + (1 - gate_weight) * pooled_s\n",
        "            fused = self.norm(fused)\n",
        "            fused = fused + self.ffn(fused)\n",
        "            return fused, gate_weight\n",
        "        else:\n",
        "            attn_ts, _ = self.cross_attn1(self.norm1(h_temporal), self.norm2(h_spectral), h_spectral)\n",
        "            attn_st, _ = self.cross_attn2(self.norm3(h_spectral), self.norm4(h_temporal), h_temporal)\n",
        "            h_t = h_temporal + self.dropout(attn_ts)\n",
        "            h_s = h_spectral + self.dropout(attn_st)\n",
        "            pooled_t = h_t.mean(dim=1)\n",
        "            pooled_s = h_s.mean(dim=1)\n",
        "            gate_input = torch.cat([pooled_t, pooled_s], dim=-1)\n",
        "            gate_weight = self.gate(gate_input)\n",
        "            fused = gate_weight * pooled_t + (1 - gate_weight) * pooled_s\n",
        "            fused = fused + self.ffn(self.norm4(fused))\n",
        "            return fused, gate_weight\n",
        "\n",
        "\n",
        "class ImprovedParametricSpectralHAR(nn.Module):\n",
        "    def __init__(self, seq_len=128, in_channels=9, num_classes=6,\n",
        "                 num_basis=64, hidden_dim=128, dropout=0.1,\n",
        "                 use_hamming=True, use_real_imag=True, use_depthwise=True,\n",
        "                 use_gated=True, simple_classifier=True, use_channel_attn=True,\n",
        "                 use_attn_pooling=True, use_learnable_time_spectral=True):\n",
        "        super().__init__()\n",
        "\n",
        "        spectral_out_dim = num_basis * 2 if use_real_imag else num_basis\n",
        "\n",
        "        self.use_channel_attn = use_channel_attn\n",
        "        self.use_attn_pooling = use_attn_pooling\n",
        "        self.use_learnable_time_spectral = use_learnable_time_spectral\n",
        "\n",
        "        if use_channel_attn:\n",
        "            self.channel_attn = ChannelAttention(in_channels)\n",
        "\n",
        "        self.spectral_operator = ImprovedSpectralOperator(\n",
        "            seq_len, in_channels, num_basis,\n",
        "            use_hamming=use_hamming,\n",
        "            use_real_imag=use_real_imag\n",
        "        )\n",
        "\n",
        "        self.spectral_conv = nn.Sequential(\n",
        "            nn.Linear(spectral_out_dim, spectral_out_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(spectral_out_dim * 2, spectral_out_dim)\n",
        "        )\n",
        "\n",
        "        if use_learnable_time_spectral:\n",
        "            self.learnable_time_spectral = LearnableTimeVaryingSpectral(spectral_out_dim, seq_len, hidden_dim)\n",
        "        else:\n",
        "            self.spectral_proj = nn.Linear(spectral_out_dim, hidden_dim)\n",
        "\n",
        "        self.temporal_encoder = ImprovedTemporalEncoder(\n",
        "            in_channels, hidden_dim,\n",
        "            use_depthwise=use_depthwise,\n",
        "            use_gated=use_gated,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.fusion = ImprovedFusion(hidden_dim, use_gated=use_gated, dropout=dropout)\n",
        "\n",
        "        if use_attn_pooling:\n",
        "            self.attn_pooling = AttentionPooling(hidden_dim)\n",
        "\n",
        "        if simple_classifier:\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "                nn.LayerNorm(hidden_dim * 2),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(hidden_dim * 2, num_classes)\n",
        "            )\n",
        "        else:\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "                nn.LayerNorm(hidden_dim * 2),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "                nn.LayerNorm(hidden_dim),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.fusion_weights_history = []\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        B, C, T = x.shape\n",
        "\n",
        "        if self.use_channel_attn:\n",
        "            x = self.channel_attn(x)\n",
        "\n",
        "        spectral = self.spectral_operator(x)\n",
        "        spectral = self.spectral_conv(spectral)\n",
        "        spectral_pooled = spectral.mean(dim=1)\n",
        "\n",
        "        if self.use_learnable_time_spectral:\n",
        "            spectral_expanded = self.learnable_time_spectral(spectral_pooled)\n",
        "        else:\n",
        "            spectral_emb = self.spectral_proj(spectral_pooled).unsqueeze(1)\n",
        "            spectral_expanded = spectral_emb.expand(B, T, -1)\n",
        "\n",
        "        temporal = self.temporal_encoder(x)\n",
        "\n",
        "        if self.use_attn_pooling:\n",
        "            temporal_pooled, temporal_attn = self.attn_pooling(temporal)\n",
        "            spectral_pooled_final, spectral_attn = self.attn_pooling(spectral_expanded)\n",
        "            gate_input = torch.cat([temporal_pooled, spectral_pooled_final], dim=-1)\n",
        "            gate_weight = self.fusion.gate(gate_input)\n",
        "            fused = gate_weight * temporal_pooled + (1 - gate_weight) * spectral_pooled_final\n",
        "            fused = self.fusion.norm(fused)\n",
        "            fused = fused + self.fusion.ffn(fused)\n",
        "        else:\n",
        "            fused, gate_weight = self.fusion(temporal, spectral_expanded)\n",
        "\n",
        "        self.fusion_weights_history.append(gate_weight.detach().cpu().mean(dim=0))\n",
        "\n",
        "        logits = self.classifier(fused)\n",
        "        return logits\n",
        "\n",
        "    def get_frequency_params(self):\n",
        "        if hasattr(self.spectral_operator, 'frequencies_logit'):\n",
        "            freqs = torch.sigmoid(self.spectral_operator.frequencies_logit) * 0.5\n",
        "            return freqs.detach().cpu().numpy()\n",
        "        return None\n",
        "\n",
        "    def get_phase_params(self):\n",
        "        if hasattr(self.spectral_operator, 'phases'):\n",
        "            return self.spectral_operator.phases.detach().cpu().numpy()\n",
        "        return None\n",
        "\n",
        "    def get_fusion_weights(self):\n",
        "        if self.fusion_weights_history:\n",
        "            return torch.stack(self.fusion_weights_history).numpy()\n",
        "        return None\n",
        "\n",
        "    def clear_fusion_weights(self):\n",
        "        self.fusion_weights_history = []\n",
        "\n",
        "\n",
        "class FFTBaseline(nn.Module):\n",
        "    def __init__(self, seq_len=128, in_channels=9, num_classes=6,\n",
        "                 hidden_dim=128, dropout=0.1, use_depthwise=True, use_gated=True):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        fft_dim = seq_len // 2 + 1\n",
        "\n",
        "        if use_depthwise:\n",
        "            self.conv1 = DepthwiseSeparableConv1d(in_channels, hidden_dim, 3, padding=1)\n",
        "            self.conv2 = DepthwiseSeparableConv1d(in_channels, hidden_dim, 5, padding=2)\n",
        "            self.conv3 = DepthwiseSeparableConv1d(in_channels, hidden_dim, 7, padding=3)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv1d(in_channels, hidden_dim, 3, padding=1)\n",
        "            self.conv2 = nn.Conv1d(in_channels, hidden_dim, 5, padding=2)\n",
        "            self.conv3 = nn.Conv1d(in_channels, hidden_dim, 7, padding=3)\n",
        "            self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
        "            self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
        "            self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
        "\n",
        "        self.fusion_conv = nn.Conv1d(hidden_dim * 3, hidden_dim, 1)\n",
        "\n",
        "        if use_gated:\n",
        "            self.gated = GatedMechanism(hidden_dim, dropout)\n",
        "        else:\n",
        "            self.attn = nn.MultiheadAttention(hidden_dim, 1, dropout=dropout, batch_first=True)\n",
        "            self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "            self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 4, hidden_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        self.fft_proj = nn.Linear(fft_dim * 2 * in_channels, hidden_dim)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim * 2),\n",
        "            nn.LayerNorm(hidden_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 2, num_classes)\n",
        "        )\n",
        "\n",
        "        self.use_depthwise = use_depthwise\n",
        "        self.use_gated = use_gated\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        B, C, T = x.shape\n",
        "\n",
        "        fft_result = torch.fft.rfft(x, dim=2)\n",
        "        fft_real = fft_result.real\n",
        "        fft_imag = fft_result.imag\n",
        "        fft_features = torch.cat([fft_real, fft_imag], dim=2)\n",
        "        fft_features = fft_features.reshape(B, -1)\n",
        "        fft_emb = self.fft_proj(fft_features)\n",
        "\n",
        "        if self.use_depthwise:\n",
        "            h1 = F.relu(self.conv1(x))\n",
        "            h2 = F.relu(self.conv2(x))\n",
        "            h3 = F.relu(self.conv3(x))\n",
        "        else:\n",
        "            h1 = F.relu(self.bn1(self.conv1(x)))\n",
        "            h2 = F.relu(self.bn2(self.conv2(x)))\n",
        "            h3 = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "        h = torch.cat([h1, h2, h3], dim=1)\n",
        "        h = self.fusion_conv(h)\n",
        "        h = h.transpose(1, 2)\n",
        "\n",
        "        if self.use_gated:\n",
        "            h = self.gated(h)\n",
        "        else:\n",
        "            h_norm = self.norm1(h)\n",
        "            attn_out, _ = self.attn(h_norm, h_norm, h_norm)\n",
        "            h = h + self.dropout(attn_out)\n",
        "            h = self.norm2(h)\n",
        "\n",
        "        h = h + self.ffn(h)\n",
        "\n",
        "        temporal_pooled = h.mean(dim=1)\n",
        "        combined = torch.cat([temporal_pooled, fft_emb], dim=1)\n",
        "\n",
        "        logits = self.classifier(combined)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class TemporalOnlyModel(nn.Module):\n",
        "    def __init__(self, seq_len=128, in_channels=9, num_classes=6,\n",
        "                 hidden_dim=128, dropout=0.1, use_depthwise=True, use_gated=True):\n",
        "        super().__init__()\n",
        "        self.temporal_encoder = ImprovedTemporalEncoder(\n",
        "            in_channels, hidden_dim,\n",
        "            use_depthwise=use_depthwise,\n",
        "            use_gated=use_gated,\n",
        "            dropout=dropout\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "            nn.LayerNorm(hidden_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 2, num_classes)\n",
        "        )\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        temporal = self.temporal_encoder(x)\n",
        "        pooled = temporal.mean(dim=1)\n",
        "        logits = self.classifier(pooled)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class SpectralOnlyModel(nn.Module):\n",
        "    def __init__(self, seq_len=128, in_channels=9, num_classes=6,\n",
        "                 num_basis=64, hidden_dim=128, dropout=0.1,\n",
        "                 use_hamming=True, use_real_imag=True):\n",
        "        super().__init__()\n",
        "        spectral_out_dim = num_basis * 2 if use_real_imag else num_basis\n",
        "\n",
        "        self.spectral_operator = ImprovedSpectralOperator(\n",
        "            seq_len, in_channels, num_basis,\n",
        "            use_hamming=use_hamming,\n",
        "            use_real_imag=use_real_imag\n",
        "        )\n",
        "        self.spectral_conv = nn.Sequential(\n",
        "            nn.Linear(spectral_out_dim, spectral_out_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(spectral_out_dim * 2, spectral_out_dim)\n",
        "        )\n",
        "        self.spectral_proj = nn.Linear(spectral_out_dim, hidden_dim)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "            nn.LayerNorm(hidden_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 2, num_classes)\n",
        "        )\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        spectral = self.spectral_operator(x)\n",
        "        spectral = self.spectral_conv(spectral)\n",
        "        spectral_pooled = spectral.mean(dim=1)\n",
        "        spectral_emb = self.spectral_proj(spectral_pooled)\n",
        "        logits = self.classifier(spectral_emb)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in test_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            logits = model(batch_x)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_y.cpu().numpy())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    return acc, f1, precision, recall\n",
        "\n",
        "\n",
        "def compute_flops_params(model, input_shape, device):\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, *input_shape).to(device)\n",
        "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
        "    flops_m = macs * 2 / 1e6\n",
        "    params_m = params / 1e6\n",
        "    return flops_m, params_m\n",
        "\n",
        "\n",
        "def measure_inference_time(model, input_shape, device, n_runs=100, warmup=10):\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, *input_shape).to(device)\n",
        "    with torch.no_grad():\n",
        "        for _ in range(warmup):\n",
        "            _ = model(dummy_input)\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.synchronize()\n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_runs):\n",
        "            _ = model(dummy_input)\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.synchronize()\n",
        "    end = time.time()\n",
        "    return (end - start) / n_runs * 1000\n",
        "\n",
        "\n",
        "def get_frequency_param_names(model):\n",
        "    freq_params = []\n",
        "    other_params = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'frequencies' in name or 'phases' in name:\n",
        "            freq_params.append(param)\n",
        "        else:\n",
        "            other_params.append(param)\n",
        "    return freq_params, other_params\n",
        "\n",
        "\n",
        "def compute_fft_spectrum(X_train, seq_len):\n",
        "    sample_signals = X_train[:100]\n",
        "    fft_results = []\n",
        "    for signal in sample_signals:\n",
        "        signal_flat = signal.reshape(-1, seq_len)\n",
        "        fft_result = np.fft.rfft(signal_flat, axis=1)\n",
        "        fft_magnitude = np.abs(fft_result)\n",
        "        fft_results.append(fft_magnitude)\n",
        "    fft_avg = np.mean(np.concatenate(fft_results, axis=0), axis=0)\n",
        "    freqs = np.fft.rfftfreq(seq_len)\n",
        "    return freqs, fft_avg\n",
        "\n",
        "\n",
        "def visualize_fft_vs_learned(dataset_name, X_train, freq_history, seq_len, save_path=None):\n",
        "    if not freq_history or len(freq_history) < 2:\n",
        "        print(f\"  Not enough frequency history to visualize for {dataset_name}\")\n",
        "        return\n",
        "\n",
        "    freqs_fft, fft_avg = compute_fft_spectrum(X_train, seq_len)\n",
        "    learned_freqs = freq_history[-1] * seq_len\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    fig.suptitle(f'FFT vs Learned Frequencies - {dataset_name}', fontsize=14, fontweight='bold')\n",
        "\n",
        "    ax1 = axes[0, 0]\n",
        "    ax1.plot(freqs_fft * seq_len, fft_avg, label='FFT Spectrum', color='blue', alpha=0.7)\n",
        "    ax1.set_xlabel('Frequency (Hz equivalent)')\n",
        "    ax1.set_ylabel('Magnitude')\n",
        "    ax1.set_title('FFT Power Spectrum (Ground Truth)')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    ax2 = axes[0, 1]\n",
        "    ax2.hist(learned_freqs, bins=30, alpha=0.7, color='red', edgecolor='black')\n",
        "    ax2.set_xlabel('Frequency (Hz equivalent)')\n",
        "    ax2.set_ylabel('Count')\n",
        "    ax2.set_title('Learned Frequency Distribution')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    ax3 = axes[1, 0]\n",
        "    ax3.plot(freqs_fft * seq_len, fft_avg, label='FFT Spectrum', color='blue', alpha=0.5, linewidth=2)\n",
        "    ax3.scatter(learned_freqs, [0] * len(learned_freqs), color='red', s=50, alpha=0.7, label='Learned Frequencies', marker='x')\n",
        "    ax3.set_xlabel('Frequency (Hz equivalent)')\n",
        "    ax3.set_ylabel('Magnitude')\n",
        "    ax3.set_title('Overlay: FFT vs Learned Frequencies')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    ax4 = axes[1, 1]\n",
        "    peak_indices = np.argsort(fft_avg)[-len(learned_freqs):]\n",
        "    peak_freqs = freqs_fft[peak_indices] * seq_len\n",
        "    sorted_learned = np.sort(learned_freqs)\n",
        "    sorted_peak = np.sort(peak_freqs)\n",
        "    freq_errors = []\n",
        "    for lf in sorted_learned:\n",
        "        min_dist = np.min(np.abs(sorted_peak - lf))\n",
        "        freq_errors.append(min_dist)\n",
        "    ax4.hist(freq_errors, bins=20, alpha=0.7, color='green', edgecolor='black')\n",
        "    ax4.set_xlabel('Distance to Nearest FFT Peak')\n",
        "    ax4.set_ylabel('Count')\n",
        "    ax4.set_title('Frequency Alignment Error')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    mean_error = np.mean(freq_errors)\n",
        "    median_error = np.median(freq_errors)\n",
        "    print(f\"\\n  FFT vs Learned Frequency Alignment for {dataset_name}:\")\n",
        "    print(f\"    Mean alignment error: {mean_error:.4f}\")\n",
        "    print(f\"    Median alignment error: {median_error:.4f}\")\n",
        "    print(f\"    % frequencies within 5Hz of FFT peaks: {np.mean(np.array(freq_errors) < 5) * 100:.1f}%\")\n",
        "\n",
        "\n",
        "def visualize_training_metrics(dataset_name, loss_history, save_path=None):\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "    fig.suptitle(f'Training Loss Curve - {dataset_name}', fontsize=14, fontweight='bold')\n",
        "\n",
        "    epochs = range(1, len(loss_history) + 1)\n",
        "    ax.plot(epochs, loss_history, marker='o', linewidth=2, markersize=4, color='blue')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Training Loss')\n",
        "    ax.set_title('Loss vs Epoch')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def visualize_fusion_weights(dataset_name, fusion_weights, save_path=None):\n",
        "    if fusion_weights is None or len(fusion_weights) == 0:\n",
        "        print(f\"  No fusion weights to visualize for {dataset_name}\")\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    fig.suptitle(f'Fusion Attention Weights - {dataset_name}', fontsize=14, fontweight='bold')\n",
        "\n",
        "    ax1 = axes[0]\n",
        "    if fusion_weights.ndim == 1:\n",
        "        batches = range(len(fusion_weights))\n",
        "        ax1.plot(batches, fusion_weights, marker='o', linewidth=1, markersize=2, alpha=0.6)\n",
        "    else:\n",
        "        for dim_idx in range(min(10, fusion_weights.shape[1])):\n",
        "            ax1.plot(fusion_weights[:, dim_idx], label=f'Dim {dim_idx}', alpha=0.6)\n",
        "        ax1.legend(fontsize=8)\n",
        "    ax1.set_xlabel('Training Step')\n",
        "    ax1.set_ylabel('Gate Weight (Temporal vs Spectral)')\n",
        "    ax1.set_title('Fusion Gate Weights Over Training')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    ax2 = axes[1]\n",
        "    if fusion_weights.ndim == 1:\n",
        "        mean_weight = np.mean(fusion_weights)\n",
        "        ax2.bar(['Temporal', 'Spectral'], [mean_weight, 1 - mean_weight], color=['blue', 'red'], alpha=0.7)\n",
        "    else:\n",
        "        mean_weights = np.mean(fusion_weights, axis=0)\n",
        "        ax2.hist(mean_weights, bins=20, color='purple', alpha=0.7, edgecolor='black')\n",
        "        ax2.axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Equal Weight')\n",
        "        ax2.legend()\n",
        "        ax2.set_xlabel('Gate Weight Distribution')\n",
        "    ax2.set_ylabel('Count / Weight')\n",
        "    ax2.set_title('Average Fusion Weight Distribution')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    if fusion_weights.ndim == 1:\n",
        "        mean_weight = np.mean(fusion_weights)\n",
        "        print(f\"\\n  Fusion Weight Statistics for {dataset_name}:\")\n",
        "        print(f\"    Mean temporal weight: {mean_weight:.4f}\")\n",
        "        print(f\"    Mean spectral weight: {1 - mean_weight:.4f}\")\n",
        "        if mean_weight > 0.55:\n",
        "            print(f\"     Model relies more on TEMPORAL features\")\n",
        "        elif mean_weight < 0.45:\n",
        "            print(f\"     Model relies more on SPECTRAL features\")\n",
        "        else:\n",
        "            print(f\"     Model uses BALANCED fusion\")\n",
        "\n",
        "\n",
        "def train_model_with_freq_lr(model, train_loader, test_loader, device, epochs=50, freq_lr=0.01, other_lr=0.001, verbose=True, use_focal_loss=False):\n",
        "    freq_params, other_params = get_frequency_param_names(model)\n",
        "    if freq_params:\n",
        "        optimizer = torch.optim.AdamW([\n",
        "            {'params': freq_params, 'lr': freq_lr},\n",
        "            {'params': other_params, 'lr': other_lr}\n",
        "        ], weight_decay=1e-4)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    else:\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=other_lr, weight_decay=1e-4)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    if use_focal_loss:\n",
        "        criterion = FocalLoss(alpha=1.0, gamma=2.0)\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    best_metrics = {}\n",
        "    best_model_state = None\n",
        "    freq_history = []\n",
        "    phase_history = []\n",
        "    loss_history = []\n",
        "\n",
        "    if hasattr(model, 'get_frequency_params') and model.get_frequency_params() is not None:\n",
        "        freq_history.append(model.get_frequency_params().copy())\n",
        "        phase_history.append(model.get_phase_params().copy())\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(batch_x)\n",
        "            loss = criterion(logits, batch_y)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        loss_history.append(avg_loss)\n",
        "        scheduler.step()\n",
        "\n",
        "        test_acc, test_f1, test_prec, test_rec = evaluate(model, test_loader, device)\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_metrics = {'acc': test_acc, 'f1': test_f1, 'prec': test_prec, 'rec': test_rec}\n",
        "            best_model_state = clean_state_dict(model.state_dict())\n",
        "\n",
        "        if hasattr(model, 'get_frequency_params') and model.get_frequency_params() is not None:\n",
        "            if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "                freq_history.append(model.get_frequency_params().copy())\n",
        "                phase_history.append(model.get_phase_params().copy())\n",
        "\n",
        "        if verbose and (epoch + 1) % 10 == 0:\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            print(f\"  Epoch {epoch+1}: Loss={avg_loss:.4f}, Acc={test_acc:.4f}, F1={test_f1:.4f}, LR={current_lr:.6f}\")\n",
        "\n",
        "    model.load_state_dict(best_model_state, strict=False)\n",
        "\n",
        "    return best_metrics, freq_history, phase_history, loss_history\n",
        "\n",
        "\n",
        "def visualize_frequency_learning(dataset_name, freq_history, phase_history, seq_len, save_path=None):\n",
        "    if not freq_history or len(freq_history) < 2:\n",
        "        print(f\"  Not enough frequency history to visualize for {dataset_name}\")\n",
        "        return\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    fig.suptitle(f'Learnable Frequency Analysis - {dataset_name}', fontsize=14, fontweight='bold')\n",
        "    init_freqs = freq_history[0]\n",
        "    final_freqs = freq_history[-1]\n",
        "    freq_change = final_freqs - init_freqs\n",
        "    ax1 = axes[0, 0]\n",
        "    x = np.arange(len(init_freqs))\n",
        "    width = 0.35\n",
        "    ax1.bar(x - width/2, init_freqs * seq_len, width, label='Initial', alpha=0.7, color='blue')\n",
        "    ax1.bar(x + width/2, final_freqs * seq_len, width, label='Learned', alpha=0.7, color='red')\n",
        "    ax1.set_xlabel('Basis Index')\n",
        "    ax1.set_ylabel('Frequency (Hz equivalent)')\n",
        "    ax1.set_title('Initial vs Learned Frequencies')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax2 = axes[0, 1]\n",
        "    colors = ['green' if c > 0 else 'red' for c in freq_change]\n",
        "    ax2.bar(x, freq_change * seq_len, color=colors, alpha=0.7)\n",
        "    ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "    ax2.set_xlabel('Basis Index')\n",
        "    ax2.set_ylabel('Frequency Change')\n",
        "    ax2.set_title('Frequency Change (Learned - Initial)')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax3 = axes[1, 0]\n",
        "    freq_array = np.array(freq_history) * seq_len\n",
        "    epochs_recorded = [0] + [i * 10 for i in range(1, len(freq_history))]\n",
        "    for i in range(0, len(init_freqs), max(1, len(init_freqs)//10)):\n",
        "        ax3.plot(epochs_recorded, freq_array[:, i], label=f'Basis {i}', alpha=0.7)\n",
        "    ax3.set_xlabel('Epoch')\n",
        "    ax3.set_ylabel('Frequency')\n",
        "    ax3.set_title('Frequency Evolution During Training')\n",
        "    ax3.legend(loc='upper right', fontsize=8, ncol=2)\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    ax4 = axes[1, 1]\n",
        "    if len(phase_history) >= 2:\n",
        "        init_phases = phase_history[0]\n",
        "        final_phases = phase_history[-1]\n",
        "        phase_change = final_phases - init_phases\n",
        "        phase_change = np.mod(phase_change + np.pi, 2 * np.pi) - np.pi\n",
        "        ax4.bar(x, phase_change, alpha=0.7, color='purple')\n",
        "        ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "        ax4.set_xlabel('Basis Index')\n",
        "        ax4.set_ylabel('Phase Change (radians)')\n",
        "        ax4.set_title('Phase Change (Learned - Initial)')\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(f\"\\n  Frequency Learning Statistics for {dataset_name}:\")\n",
        "    print(f\"    Mean absolute frequency change: {np.mean(np.abs(freq_change)) * seq_len:.4f}\")\n",
        "    print(f\"    Max frequency change: {np.max(np.abs(freq_change)) * seq_len:.4f}\")\n",
        "    print(f\"    Std of frequency change: {np.std(freq_change) * seq_len:.4f}\")\n",
        "    print(f\"    % frequencies that increased: {np.mean(freq_change > 0) * 100:.1f}%\")\n",
        "    print(f\"    % frequencies that decreased: {np.mean(freq_change < 0) * 100:.1f}%\")\n",
        "\n",
        "\n",
        "def run_ablation_study(dataset_name, X_train, y_train, X_test, y_test, activity_names, device, epochs=50, freq_lr=0.001, other_lr=0.001):\n",
        "    seq_len = X_train.shape[1]\n",
        "    input_dim = X_train.shape[2]\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    train_dataset = UCIHARDataset(X_train, y_train)\n",
        "    test_dataset = UCIHARDataset(X_test, y_test)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, pin_memory=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, pin_memory=True, num_workers=2)\n",
        "    ablation_configs = [\n",
        "        ('Full Model', {'type': 'full', 'hamming': True, 'real_imag': True, 'depthwise': True, 'gated': True, 'simple_clf': True, 'channel_attn': True, 'attn_pooling': True, 'learnable_time': True}),\n",
        "        ('FFT Baseline', {'type': 'fft'}),\n",
        "        ('w/o Spectral Path', {'type': 'temporal_only'}),\n",
        "        ('w/o Temporal Path', {'type': 'spectral_only'}),\n",
        "        ('w/o Hamming Window', {'type': 'full', 'hamming': False, 'real_imag': True, 'depthwise': True, 'gated': True, 'simple_clf': True, 'channel_attn': True, 'attn_pooling': True, 'learnable_time': True}),\n",
        "        ('Magnitude Only', {'type': 'full', 'hamming': True, 'real_imag': False, 'depthwise': True, 'gated': True, 'simple_clf': True, 'channel_attn': True, 'attn_pooling': True, 'learnable_time': True}),\n",
        "        ('Standard Conv', {'type': 'full', 'hamming': True, 'real_imag': True, 'depthwise': False, 'gated': True, 'simple_clf': True, 'channel_attn': True, 'attn_pooling': True, 'learnable_time': True}),\n",
        "        ('Attention Fusion', {'type': 'full', 'hamming': True, 'real_imag': True, 'depthwise': True, 'gated': False, 'simple_clf': True, 'channel_attn': True, 'attn_pooling': True, 'learnable_time': True}),\n",
        "        ('3-Layer Classifier', {'type': 'full', 'hamming': True, 'real_imag': True, 'depthwise': True, 'gated': True, 'simple_clf': False, 'channel_attn': True, 'attn_pooling': True, 'learnable_time': True}),\n",
        "        ('w/o Channel Attention', {'type': 'full', 'hamming': True, 'real_imag': True, 'depthwise': True, 'gated': True, 'simple_clf': True, 'channel_attn': False, 'attn_pooling': True, 'learnable_time': True}),\n",
        "        ('w/o Attention Pooling', {'type': 'full', 'hamming': True, 'real_imag': True, 'depthwise': True, 'gated': True, 'simple_clf': True, 'channel_attn': True, 'attn_pooling': False, 'learnable_time': True}),\n",
        "        ('w/o Learnable Time Spectral', {'type': 'full', 'hamming': True, 'real_imag': True, 'depthwise': True, 'gated': True, 'simple_clf': True, 'channel_attn': True, 'attn_pooling': True, 'learnable_time': False}),\n",
        "    ]\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"ABLATION STUDY - {dataset_name}\")\n",
        "    print(f\"Frequency LR: {freq_lr}, Other LR: {other_lr}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    ablation_results = []\n",
        "    full_model_acc = None\n",
        "    full_model_state = None\n",
        "    full_model_freq_history = None\n",
        "    full_model_phase_history = None\n",
        "    full_model_loss_history = None\n",
        "    full_model = None\n",
        "    for config_name, config in ablation_configs:\n",
        "        print(f\"\\n--- {config_name} ---\")\n",
        "        if config['type'] == 'temporal_only':\n",
        "            model = TemporalOnlyModel(\n",
        "                seq_len=seq_len,\n",
        "                in_channels=input_dim,\n",
        "                num_classes=num_classes,\n",
        "                hidden_dim=128,\n",
        "                dropout=0.2,\n",
        "                use_depthwise=True,\n",
        "                use_gated=True\n",
        "            ).to(device)\n",
        "        elif config['type'] == 'spectral_only':\n",
        "            model = SpectralOnlyModel(\n",
        "                seq_len=seq_len,\n",
        "                in_channels=input_dim,\n",
        "                num_classes=num_classes,\n",
        "                num_basis=64,\n",
        "                hidden_dim=128,\n",
        "                dropout=0.2,\n",
        "                use_hamming=True,\n",
        "                use_real_imag=True\n",
        "            ).to(device)\n",
        "        elif config['type'] == 'fft':\n",
        "            model = FFTBaseline(\n",
        "                seq_len=seq_len,\n",
        "                in_channels=input_dim,\n",
        "                num_classes=num_classes,\n",
        "                hidden_dim=128,\n",
        "                dropout=0.2,\n",
        "                use_depthwise=True,\n",
        "                use_gated=True\n",
        "            ).to(device)\n",
        "        else:\n",
        "            model = ImprovedParametricSpectralHAR(\n",
        "                seq_len=seq_len,\n",
        "                in_channels=input_dim,\n",
        "                num_classes=num_classes,\n",
        "                num_basis=64,\n",
        "                hidden_dim=128,\n",
        "                dropout=0.2,\n",
        "                use_hamming=config['hamming'],\n",
        "                use_real_imag=config['real_imag'],\n",
        "                use_depthwise=config['depthwise'],\n",
        "                use_gated=config['gated'],\n",
        "                simple_classifier=config['simple_clf'],\n",
        "                use_channel_attn=config.get('channel_attn', True),\n",
        "                use_attn_pooling=config.get('attn_pooling', True),\n",
        "                use_learnable_time_spectral=config.get('learnable_time', True)\n",
        "            ).to(device)\n",
        "        flops_m, params_m = compute_flops_params(model, (seq_len, input_dim), device)\n",
        "        inf_time = measure_inference_time(model, (seq_len, input_dim), device)\n",
        "        use_focal = (config_name == 'Full Model')\n",
        "        best_metrics, freq_history, phase_history, loss_history = train_model_with_freq_lr(\n",
        "            model, train_loader, test_loader, device,\n",
        "            epochs=epochs, freq_lr=freq_lr, other_lr=other_lr, verbose=False, use_focal_loss=use_focal\n",
        "        )\n",
        "        if config_name == 'Full Model':\n",
        "            full_model_acc = best_metrics['acc']\n",
        "            full_model_state = clean_state_dict(model.state_dict())\n",
        "            full_model_freq_history = freq_history\n",
        "            full_model_phase_history = phase_history\n",
        "            full_model_loss_history = loss_history\n",
        "            full_model = model\n",
        "            delta = '-'\n",
        "        else:\n",
        "            delta = f\"{(best_metrics['acc'] - full_model_acc) * 100:.1f}%\"\n",
        "        print(f\"  Acc: {best_metrics['acc']:.4f} | F1: {best_metrics['f1']:.4f} | Params: {params_m:.2f}M | FLOPs: {flops_m:.2f}M | Inf: {inf_time:.2f}ms | Delta: {delta}\")\n",
        "        ablation_results.append({\n",
        "            'Dataset': dataset_name,\n",
        "            'Configuration': config_name,\n",
        "            'Acc': round(best_metrics['acc'], 4),\n",
        "            'F1': round(best_metrics['f1'], 4),\n",
        "            'Params(M)': round(params_m, 2),\n",
        "            'FLOPs(M)': round(flops_m, 2),\n",
        "            'Inf(ms)': round(inf_time, 2),\n",
        "            'Delta': delta\n",
        "        })\n",
        "    if full_model_freq_history:\n",
        "        print(f\"\\n--- Visualizing Frequency Learning for {dataset_name} ---\")\n",
        "        visualize_frequency_learning(\n",
        "            dataset_name,\n",
        "            full_model_freq_history,\n",
        "            full_model_phase_history,\n",
        "            seq_len,\n",
        "            save_path=f'{dataset_name}_frequency_learning.png'\n",
        "        )\n",
        "    if full_model_freq_history:\n",
        "        print(f\"\\n--- Visualizing FFT vs Learned Frequencies for {dataset_name} ---\")\n",
        "        visualize_fft_vs_learned(\n",
        "            dataset_name,\n",
        "            X_train,\n",
        "            full_model_freq_history,\n",
        "            seq_len,\n",
        "            save_path=f'{dataset_name}_fft_vs_learned.png'\n",
        "        )\n",
        "    if full_model_loss_history:\n",
        "        print(f\"\\n--- Visualizing Training Loss for {dataset_name} ---\")\n",
        "        visualize_training_metrics(\n",
        "            dataset_name,\n",
        "            full_model_loss_history,\n",
        "            save_path=f'{dataset_name}_training_loss.png'\n",
        "        )\n",
        "    if full_model is not None and hasattr(full_model, 'get_fusion_weights'):\n",
        "        fusion_weights = full_model.get_fusion_weights()\n",
        "        if fusion_weights is not None:\n",
        "            print(f\"\\n--- Visualizing Fusion Weights for {dataset_name} ---\")\n",
        "            visualize_fusion_weights(\n",
        "                dataset_name,\n",
        "                fusion_weights,\n",
        "                save_path=f'{dataset_name}_fusion_weights.png'\n",
        "            )\n",
        "    return ablation_results, full_model_state\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Improved PSN (Parametric Spectral Network) Multi-Dataset Training\")\n",
        "    print(\"with Ablation Study and Frequency Learning Visualization\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Device: {device}\\n\")\n",
        "    OTHER_LR = 0.001\n",
        "    FREQ_LR = OTHER_LR * 0.1\n",
        "    EPOCHS = 50\n",
        "    print(f\"Hyperparameters:\")\n",
        "    print(f\"  Frequency LR: {FREQ_LR}\")\n",
        "    print(f\"  Other LR: {OTHER_LR}\")\n",
        "    print(f\"  Epochs: {EPOCHS}\")\n",
        "    datasets_config = [\n",
        "        ('UCI-HAR', load_uci_har, '/content/drive/MyDrive/HAR_Dataset/UCI'),\n",
        "        #('WISDM', load_wisdm_data, '/content/drive/MyDrive/HAR_Dataset/WISDM'),\n",
        "        #('MotionSense', load_motionsense_data, '/content/drive/MyDrive/HAR_Dataset/MOTIONSENSE'),\n",
        "        #('UniMiB', load_unimib_shar_data, '/content/drive/MyDrive/HAR_Dataset/UNIMIB (1)'),\n",
        "        #('DSADS', load_dsads_data, '/content/drive/MyDrive/HAR_Dataset/DSADS'),\n",
        "        #('PAMAP2', load_pamap2_data, '/content/drive/MyDrive/HAR_Dataset/PAMAP2'),\n",
        "        #('MHEALTH', load_mhealth_data, '/content/drive/MyDrive/HAR_Dataset/MHEALTH')\n",
        "    ]\n",
        "    all_datasets = {}\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Loading All Datasets\")\n",
        "    print(\"=\" * 80)\n",
        "    for dataset_name, loader_func, data_path in datasets_config:\n",
        "        try:\n",
        "            print(f\"\\n{'#'*60}\")\n",
        "            print(f\"Loading {dataset_name}...\")\n",
        "            print(f\"{'#'*60}\")\n",
        "            data = loader_func(data_path)\n",
        "            if data is None or data[0] is None:\n",
        "                print(f\"Failed to load {dataset_name}\")\n",
        "                continue\n",
        "            X_train, y_train, X_test, y_test, activity_names = data\n",
        "            num_train_classes = len(np.unique(y_train))\n",
        "            num_test_classes = len(np.unique(y_test))\n",
        "            print(f\"Train: {X_train.shape} | Classes: {num_train_classes}\")\n",
        "            print(f\"Test: {X_test.shape} | Classes: {num_test_classes}\")\n",
        "            print(f\"Activity Names: {activity_names}\")\n",
        "            train_class_dist = Counter(y_train)\n",
        "            test_class_dist = Counter(y_test)\n",
        "            print(f\"Train class distribution: {dict(sorted(train_class_dist.items()))}\")\n",
        "            print(f\"Test class distribution: {dict(sorted(test_class_dist.items()))}\")\n",
        "            all_datasets[dataset_name] = {\n",
        "                'X_train': X_train,\n",
        "                'y_train': y_train,\n",
        "                'X_test': X_test,\n",
        "                'y_test': y_test,\n",
        "                'activity_names': activity_names\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {dataset_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Successfully loaded {len(all_datasets)} datasets\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "    all_ablation_results = []\n",
        "    for dataset_name, dataset_data in all_datasets.items():\n",
        "        try:\n",
        "            ablation_results, full_model_state = run_ablation_study(\n",
        "                dataset_name,\n",
        "                dataset_data['X_train'],\n",
        "                dataset_data['y_train'],\n",
        "                dataset_data['X_test'],\n",
        "                dataset_data['y_test'],\n",
        "                dataset_data['activity_names'],\n",
        "                device,\n",
        "                epochs=EPOCHS,\n",
        "                freq_lr=FREQ_LR,\n",
        "                other_lr=OTHER_LR\n",
        "            )\n",
        "            all_ablation_results.extend(ablation_results)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {dataset_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    print(f\"\\n{'#'*80}\")\n",
        "    print(f\"{'#'*80}\")\n",
        "    print(\"FINAL SUMMARY - ALL RESULTS\")\n",
        "    print(f\"{'#'*80}\")\n",
        "    print(f\"{'#'*80}\\n\")\n",
        "    if all_ablation_results:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"ABLATION STUDY RESULTS\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "        ablation_df = pd.DataFrame(all_ablation_results)\n",
        "        for dataset_name in ablation_df['Dataset'].unique():\n",
        "            print(f\"\\n--- {dataset_name} ---\")\n",
        "            dataset_ablation = ablation_df[ablation_df['Dataset'] == dataset_name]\n",
        "            print(dataset_ablation[['Configuration', 'Acc', 'F1', 'Params(M)', 'FLOPs(M)', 'Inf(ms)', 'Delta']].to_string(index=False))\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"ALL EXPERIMENTS COMPLETED!\")\n",
        "    print(f\"{'='*80}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w4KlwTRfZsDR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}