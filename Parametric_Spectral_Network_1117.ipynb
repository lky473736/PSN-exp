{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Enhanced Parametric Spectral Network for Human Activity Recognition\n",
        "- ì„±ëŠ¥ ê°œì„ : Multi-resolution freq init, Complex weights, Gating fusion\n",
        "- Data augmentation ì—†ì´ architectural improvementsë§Œ ì ìš©\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import math\n",
        "\n",
        "# ============================================================================\n",
        "# 1. Data Loading (UCI-HAR)\n",
        "# ============================================================================\n",
        "\n",
        "class UCIHARDataset(Dataset):\n",
        "    def __init__(self, data_dir, split='train'):\n",
        "        self.split = split\n",
        "\n",
        "        if split == 'train':\n",
        "            signals_dir = os.path.join(data_dir, 'train', 'Inertial Signals')\n",
        "            labels_file = os.path.join(data_dir, 'train', 'y_train.txt')\n",
        "        else:\n",
        "            signals_dir = os.path.join(data_dir, 'test', 'Inertial Signals')\n",
        "            labels_file = os.path.join(data_dir, 'test', 'y_test.txt')\n",
        "\n",
        "        signal_types = [\n",
        "            'body_acc_x', 'body_acc_y', 'body_acc_z',\n",
        "            'body_gyro_x', 'body_gyro_y', 'body_gyro_z',\n",
        "            'total_acc_x', 'total_acc_y', 'total_acc_z'\n",
        "        ]\n",
        "\n",
        "        signals = []\n",
        "        for signal_type in signal_types:\n",
        "            filename = f\"{signal_type}_{split}.txt\"\n",
        "            filepath = os.path.join(signals_dir, filename)\n",
        "            signal = np.loadtxt(filepath)\n",
        "            signals.append(signal)\n",
        "\n",
        "        self.data = np.stack(signals, axis=1).astype(np.float32)\n",
        "        self.labels = np.loadtxt(labels_file, dtype=np.int64) - 1\n",
        "\n",
        "        print(f\"[{split}] Loaded {len(self.labels)} samples, shape: {self.data.shape}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.data[idx]), self.labels[idx]\n",
        "\n",
        "# ============================================================================\n",
        "# 2. Enhanced Parametric Spectral Operator\n",
        "# ============================================================================\n",
        "\n",
        "class EnhancedSpectralOperator(nn.Module):\n",
        "    \"\"\"\n",
        "    ê°œì„ ì‚¬í•­:\n",
        "    1. Multi-resolution frequency initialization (low/mid/high bands)\n",
        "    2. Complex-valued channel weights (real + imaginary)\n",
        "    3. Channel-wise learnable normalization\n",
        "    \"\"\"\n",
        "    def __init__(self, seq_len, in_channels, num_basis=64):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.in_channels = in_channels\n",
        "        self.num_basis = num_basis\n",
        "\n",
        "        self.register_buffer('t', torch.arange(seq_len).float())\n",
        "\n",
        "        # Multi-resolution initialization\n",
        "        low_band = num_basis // 3\n",
        "        mid_band = num_basis // 3\n",
        "        high_band = num_basis - low_band - mid_band\n",
        "\n",
        "        freqs_low = torch.linspace(0, seq_len//8, low_band) / seq_len\n",
        "        freqs_mid = torch.linspace(seq_len//8, seq_len//4, mid_band) / seq_len\n",
        "        freqs_high = torch.linspace(seq_len//4, seq_len//2, high_band) / seq_len\n",
        "        init_freqs = torch.cat([freqs_low, freqs_mid, freqs_high])\n",
        "\n",
        "        self.frequencies = nn.Parameter(init_freqs)\n",
        "        self.phases = nn.Parameter(torch.zeros(num_basis))\n",
        "\n",
        "        # Complex-valued weights\n",
        "        self.channel_weights_real = nn.Parameter(torch.randn(in_channels, num_basis) * 0.02)\n",
        "        self.channel_weights_imag = nn.Parameter(torch.randn(in_channels, num_basis) * 0.02)\n",
        "\n",
        "        # Channel-wise normalization\n",
        "        self.gamma = nn.Parameter(torch.ones(in_channels, 1))\n",
        "        self.beta = nn.Parameter(torch.zeros(in_channels, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, T = x.shape\n",
        "\n",
        "        # Construct basis\n",
        "        args = 2 * np.pi * self.frequencies.unsqueeze(1) * self.t.unsqueeze(0) + self.phases.unsqueeze(1)\n",
        "        basis_real = torch.cos(args)\n",
        "        basis_imag = -torch.sin(args)\n",
        "\n",
        "        # Spectral transform\n",
        "        spectral_real = torch.einsum('bct,ft->bcf', x, basis_real)\n",
        "        spectral_imag = torch.einsum('bct,ft->bcf', x, basis_imag)\n",
        "\n",
        "        # Complex multiplication: (a + bi) * (c + di) = (ac - bd) + (ad + bc)i\n",
        "        weighted_real = spectral_real * (1 + self.channel_weights_real.unsqueeze(0)) - \\\n",
        "                       spectral_imag * self.channel_weights_imag.unsqueeze(0)\n",
        "        weighted_imag = spectral_real * self.channel_weights_imag.unsqueeze(0) + \\\n",
        "                       spectral_imag * (1 + self.channel_weights_real.unsqueeze(0))\n",
        "\n",
        "        # Magnitude\n",
        "        spectral_mag = torch.sqrt(weighted_real**2 + weighted_imag**2 + 1e-8)\n",
        "        spectral_mag = spectral_mag / math.sqrt(self.seq_len)\n",
        "\n",
        "        # Channel-wise normalization\n",
        "        spectral_mag = spectral_mag * self.gamma.unsqueeze(0) + self.beta.unsqueeze(0)\n",
        "\n",
        "        return spectral_mag\n",
        "\n",
        "# ============================================================================\n",
        "# 3. Enhanced Attention Modules\n",
        "# ============================================================================\n",
        "\n",
        "class SpectralAttention(nn.Module):\n",
        "    def __init__(self, num_basis, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = num_basis // num_heads\n",
        "\n",
        "        self.qkv = nn.Linear(num_basis, num_basis * 3)\n",
        "        self.proj = nn.Linear(num_basis, num_basis)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = nn.LayerNorm(num_basis)\n",
        "\n",
        "        # Learnable temperature\n",
        "        self.temperature = nn.Parameter(torch.ones(1) * math.sqrt(self.head_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, F_dim = x.shape\n",
        "\n",
        "        outputs = []\n",
        "        for c in range(C):\n",
        "            x_c = x[:, c, :]\n",
        "            x_norm = self.norm(x_c)\n",
        "\n",
        "            qkv = self.qkv(x_norm).reshape(B, 3, self.num_heads, self.head_dim).permute(1, 0, 2, 3)\n",
        "            q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "            attn = (q @ k.transpose(-2, -1)) / self.temperature\n",
        "            attn = F.softmax(attn, dim=-1)\n",
        "            attn = self.dropout(attn)\n",
        "\n",
        "            out = (attn @ v).reshape(B, F_dim)\n",
        "            out = self.proj(out)\n",
        "            out = self.dropout(out)\n",
        "            out = out + x_c\n",
        "            outputs.append(out)\n",
        "\n",
        "        return torch.stack(outputs, dim=1)\n",
        "\n",
        "class EnhancedCrossDomainFusion(nn.Module):\n",
        "    \"\"\"\n",
        "    ê°œì„ ì‚¬í•­:\n",
        "    1. Bidirectional cross-attention\n",
        "    2. Adaptive gating mechanism\n",
        "    3. Feed-forward network\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_dim, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.cross_attn1 = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.cross_attn2 = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "\n",
        "        # Gating mechanism\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # FFN\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 4, hidden_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm4 = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, h_temporal, h_spectral):\n",
        "        # Cross attention\n",
        "        attn_ts, _ = self.cross_attn1(self.norm1(h_temporal), self.norm2(h_spectral), h_spectral)\n",
        "        attn_st, _ = self.cross_attn2(self.norm3(h_spectral), self.norm4(h_temporal), h_temporal)\n",
        "\n",
        "        h_t = h_temporal + self.dropout(attn_ts)\n",
        "        h_s = h_spectral + self.dropout(attn_st)\n",
        "\n",
        "        # Pooling\n",
        "        pooled_t = h_t.mean(dim=1)  # (B, D)\n",
        "        pooled_s = h_s.mean(dim=1)  # (B, D)\n",
        "\n",
        "        # Adaptive gating\n",
        "        gate_input = torch.cat([pooled_t, pooled_s], dim=-1)\n",
        "        gate_weight = self.gate(gate_input)\n",
        "\n",
        "        # Gated fusion\n",
        "        fused = gate_weight * pooled_t + (1 - gate_weight) * pooled_s\n",
        "\n",
        "        # FFN\n",
        "        fused = fused + self.ffn(self.norm4(fused))\n",
        "\n",
        "        return fused\n",
        "\n",
        "# ============================================================================\n",
        "# 4. Enhanced Temporal Encoder\n",
        "# ============================================================================\n",
        "\n",
        "class EnhancedTemporalEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dim, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # Multi-scale convolution\n",
        "        self.conv1 = nn.Conv1d(in_channels, hidden_dim, 3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels, hidden_dim, 5, padding=2)\n",
        "        self.conv3 = nn.Conv1d(in_channels, hidden_dim, 7, padding=3)\n",
        "\n",
        "        self.fusion_conv = nn.Conv1d(hidden_dim * 3, hidden_dim, 1)\n",
        "\n",
        "        self.attn = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 4, hidden_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Multi-scale feature extraction\n",
        "        h1 = F.relu(self.conv1(x))\n",
        "        h2 = F.relu(self.conv2(x))\n",
        "        h3 = F.relu(self.conv3(x))\n",
        "\n",
        "        h = torch.cat([h1, h2, h3], dim=1)\n",
        "        h = self.fusion_conv(h)  # (B, D, T)\n",
        "\n",
        "        h = h.transpose(1, 2)  # (B, T, D)\n",
        "\n",
        "        # Self-attention\n",
        "        h_norm = self.norm1(h)\n",
        "        attn_out, _ = self.attn(h_norm, h_norm, h_norm)\n",
        "        h = h + self.dropout(attn_out)\n",
        "\n",
        "        # FFN\n",
        "        h = h + self.ffn(self.norm2(h))\n",
        "\n",
        "        return h\n",
        "\n",
        "# ============================================================================\n",
        "# 5. Full Enhanced Model\n",
        "# ============================================================================\n",
        "\n",
        "class EnhancedParametricSpectralHAR(nn.Module):\n",
        "    def __init__(self, seq_len=128, in_channels=9, num_classes=6,\n",
        "                 num_basis=64, hidden_dim=128, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Enhanced spectral operator\n",
        "        self.spectral_operator = EnhancedSpectralOperator(seq_len, in_channels, num_basis)\n",
        "\n",
        "        # Spectral processing\n",
        "        self.spectral_conv = nn.Sequential(\n",
        "            nn.Linear(num_basis, num_basis * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(num_basis * 2, num_basis)\n",
        "        )\n",
        "        self.spectral_attn = SpectralAttention(num_basis, num_heads, dropout)\n",
        "        self.spectral_proj = nn.Linear(num_basis, hidden_dim)\n",
        "\n",
        "        # Enhanced temporal encoder\n",
        "        self.temporal_encoder = EnhancedTemporalEncoder(in_channels, hidden_dim, num_heads, dropout)\n",
        "\n",
        "        # Enhanced fusion\n",
        "        self.fusion = EnhancedCrossDomainFusion(hidden_dim, num_heads, dropout)\n",
        "\n",
        "        # Classifier with stronger capacity\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "            nn.LayerNorm(hidden_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, T = x.shape\n",
        "\n",
        "        # Spectral path\n",
        "        spectral = self.spectral_operator(x)  # (B, C, F)\n",
        "        spectral = self.spectral_conv(spectral)\n",
        "        spectral = self.spectral_attn(spectral)\n",
        "\n",
        "        spectral_pooled = spectral.mean(dim=1)  # (B, F)\n",
        "        spectral_emb = self.spectral_proj(spectral_pooled).unsqueeze(1)  # (B, 1, D)\n",
        "\n",
        "        # Temporal path\n",
        "        temporal = self.temporal_encoder(x)  # (B, T, D)\n",
        "\n",
        "        # Fusion\n",
        "        spectral_expanded = spectral_emb.expand(B, temporal.size(1), -1)\n",
        "        fused = self.fusion(temporal, spectral_expanded)\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(fused)\n",
        "        return logits\n",
        "\n",
        "# ============================================================================\n",
        "# 6. Training Utilities with Label Smoothing & Mixup\n",
        "# ============================================================================\n",
        "\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        n_class = pred.size(1)\n",
        "        one_hot = torch.zeros_like(pred).scatter(1, target.unsqueeze(1), 1)\n",
        "        one_hot = one_hot * (1 - self.smoothing) + self.smoothing / n_class\n",
        "        log_prob = F.log_softmax(pred, dim=1)\n",
        "        loss = -(one_hot * log_prob).sum(dim=1).mean()\n",
        "        return loss\n",
        "\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    \"\"\"Mixup augmentation\"\"\"\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def train_epoch(model, loader, optimizer, device, use_mixup=True):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "    criterion = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
        "    criterion_ce = nn.CrossEntropyLoss()\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if use_mixup and np.random.rand() < 0.5:\n",
        "            mixed_x, y_a, y_b, lam = mixup_data(x, y, alpha=0.2)\n",
        "            logits = model(mixed_x)\n",
        "            loss = lam * criterion_ce(logits, y_a) + (1 - lam) * criterion_ce(logits, y_b)\n",
        "        else:\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "    return total_loss / len(loader), accuracy_score(all_labels, all_preds)\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            preds = logits.argmax(dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "    return accuracy_score(all_labels, all_preds), f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "# ============================================================================\n",
        "# 7. Main Execution\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    # Config\n",
        "    DATA_DIR = '/content/drive/MyDrive/Colab Notebooks/UCI-HAR/UCI-HAR'\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    EPOCHS = 150\n",
        "    BATCH_SIZE = 64\n",
        "    LR = 5e-4\n",
        "    WARMUP_EPOCHS = 10\n",
        "\n",
        "    print(f\"Device: {DEVICE}\")\n",
        "\n",
        "    # Data\n",
        "    train_dataset = UCIHARDataset(DATA_DIR, split='train')\n",
        "    test_dataset = UCIHARDataset(DATA_DIR, split='test')\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Model\n",
        "    model = EnhancedParametricSpectralHAR(\n",
        "        seq_len=128, in_channels=9, num_classes=6,\n",
        "        num_basis=64, hidden_dim=128, num_heads=4, dropout=0.2\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    print(f\"Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    # Optimizer with weight decay\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=5e-4)\n",
        "\n",
        "    # Warmup + Cosine scheduler\n",
        "    warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
        "        optimizer, start_factor=0.1, end_factor=1.0, total_iters=WARMUP_EPOCHS\n",
        "    )\n",
        "    cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer, T_max=EPOCHS - WARMUP_EPOCHS, eta_min=1e-6\n",
        "    )\n",
        "    scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
        "        optimizer, schedulers=[warmup_scheduler, cosine_scheduler], milestones=[WARMUP_EPOCHS]\n",
        "    )\n",
        "\n",
        "    # Training\n",
        "    best_acc = 0.0\n",
        "    patience = 0\n",
        "    MAX_PATIENCE = 30\n",
        "\n",
        "    print(\"\\nðŸš€ Starting Enhanced Training...\")\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, DEVICE, use_mixup=True)\n",
        "        test_acc, test_f1 = evaluate(model, test_loader, DEVICE)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            patience = 0\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'test_acc': test_acc,\n",
        "                'test_f1': test_f1\n",
        "            }, 'best_enhanced_har.pth')\n",
        "        else:\n",
        "            patience += 1\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch+1:03d}/{EPOCHS} | Loss: {train_loss:.4f} | \"\n",
        "                  f\"Train: {train_acc:.4f} | Test: {test_acc:.4f} | F1: {test_f1:.4f} | \"\n",
        "                  f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        if patience >= MAX_PATIENCE:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nâœ… Best Test Accuracy: {best_acc:.4f}\")\n",
        "\n",
        "    # Interpretability\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"INTERPRETABILITY ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    checkpoint = torch.load('best_enhanced_har.pth')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    learned_freqs = model.spectral_operator.frequencies.detach().cpu().numpy()\n",
        "    learned_freqs_hz = np.sort(learned_freqs * 50)  # Convert to Hz (50Hz sampling)\n",
        "\n",
        "    print(\"Top 10 Learned Frequencies (Hz):\")\n",
        "    print(learned_freqs_hz[:10])\n",
        "    print(f\"\\nDistribution: Mean={np.mean(learned_freqs_hz):.2f}Hz, Std={np.std(learned_freqs_hz):.2f}Hz\")\n",
        "    print(f\"Final Test Acc: {checkpoint['test_acc']:.4f}, F1: {checkpoint['test_f1']:.4f}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOWz65yK9TNb",
        "outputId": "9228e71a-8131-4549-8ee5-a11b6f3914dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "[train] Loaded 7352 samples, shape: (7352, 9, 128)\n",
            "[test] Loaded 2947 samples, shape: (2947, 9, 128)\n",
            "Model Parameters: 673,369\n",
            "\n",
            "ðŸš€ Starting Enhanced Training...\n",
            "Epoch 005/150 | Loss: 0.5087 | Train: 0.7144 | Test: 0.9223 | F1: 0.9229 | LR: 0.000275\n",
            "Epoch 010/150 | Loss: 0.4811 | Train: 0.7624 | Test: 0.9169 | F1: 0.9171 | LR: 0.000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 015/150 | Loss: 0.4488 | Train: 0.7727 | Test: 0.9308 | F1: 0.9303 | LR: 0.000498\n",
            "Epoch 020/150 | Loss: 0.4482 | Train: 0.7934 | Test: 0.9484 | F1: 0.9486 | LR: 0.000494\n",
            "Epoch 025/150 | Loss: 0.4268 | Train: 0.7675 | Test: 0.9511 | F1: 0.9513 | LR: 0.000486\n",
            "Epoch 030/150 | Loss: 0.4198 | Train: 0.7690 | Test: 0.9410 | F1: 0.9407 | LR: 0.000475\n",
            "Epoch 035/150 | Loss: 0.3827 | Train: 0.7756 | Test: 0.9399 | F1: 0.9394 | LR: 0.000462\n",
            "Epoch 040/150 | Loss: 0.4010 | Train: 0.7807 | Test: 0.9328 | F1: 0.9321 | LR: 0.000446\n",
            "Epoch 045/150 | Loss: 0.4250 | Train: 0.7956 | Test: 0.9403 | F1: 0.9400 | LR: 0.000427\n",
            "Epoch 050/150 | Loss: 0.3945 | Train: 0.8268 | Test: 0.9440 | F1: 0.9437 | LR: 0.000406\n",
            "Epoch 055/150 | Loss: 0.4239 | Train: 0.8313 | Test: 0.9396 | F1: 0.9389 | LR: 0.000383\n",
            "Epoch 060/150 | Loss: 0.3818 | Train: 0.7976 | Test: 0.9522 | F1: 0.9518 | LR: 0.000359\n",
            "Epoch 065/150 | Loss: 0.3720 | Train: 0.7560 | Test: 0.9471 | F1: 0.9469 | LR: 0.000333\n",
            "Epoch 070/150 | Loss: 0.3756 | Train: 0.8305 | Test: 0.9481 | F1: 0.9479 | LR: 0.000306\n",
            "Epoch 075/150 | Loss: 0.3646 | Train: 0.8135 | Test: 0.9528 | F1: 0.9525 | LR: 0.000278\n",
            "Early stopping at epoch 77\n",
            "\n",
            "âœ… Best Test Accuracy: 0.9566\n",
            "\n",
            "============================================================\n",
            "INTERPRETABILITY ANALYSIS\n",
            "============================================================\n",
            "Top 10 Learned Frequencies (Hz):\n",
            "[-1.3925166  -0.31136453  0.4560218   0.8154359   1.5750163   1.6832184\n",
            "  2.4773524   2.7243798   2.7399757   2.7468483 ]\n",
            "\n",
            "Distribution: Mean=10.45Hz, Std=7.13Hz\n",
            "Final Test Acc: 0.9566, F1: 0.9569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xeT0_zkF_Ahe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "emEglhAo9TRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oei4t9Ig6RI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JBOE-FV86qUT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}