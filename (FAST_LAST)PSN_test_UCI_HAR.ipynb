{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TRU2lkv-Ya_1",
        "outputId": "31b1a950-c0ae-4435-ae7e-80353e93c949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.12/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: ptflops in /usr/local/lib/python3.12/dist-packages (0.7.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->thop) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->thop) (3.0.3)\n",
            "================================================================================\n",
            "PSN (Parametric Spectral Network) Multi-Dataset Training & Analysis\n",
            "================================================================================\n",
            "Device: cuda\n",
            "\n",
            "Hyperparameters:\n",
            "  Frequency LR: 0.001\n",
            "  Other LR: 0.001\n",
            "  Epochs: 50\n",
            "================================================================================\n",
            "Loading Datasets\n",
            "================================================================================\n",
            "\n",
            "############################################################\n",
            "Loading UCI-HAR...\n",
            "############################################################\n",
            "Train: (7352, 128, 9) | Classes: 6\n",
            "Test: (2947, 128, 9) | Classes: 6\n",
            "Activity Names: ['Walking', 'Walking Upstairs', 'Walking Downstairs', 'Sitting', 'Standing', 'Laying']\n",
            "Train class distribution: {np.int64(0): 1226, np.int64(1): 1073, np.int64(2): 986, np.int64(3): 1286, np.int64(4): 1374, np.int64(5): 1407}\n",
            "Test class distribution: {np.int64(0): 496, np.int64(1): 471, np.int64(2): 420, np.int64(3): 491, np.int64(4): 532, np.int64(5): 537}\n",
            "\n",
            "================================================================================\n",
            "Successfully loaded 1 datasets\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ABLATION STUDY - UCI-HAR\n",
            "Frequency LR: 0.001, Other LR: 0.001\n",
            "================================================================================\n",
            "\n",
            "--- Full Model ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-485098798.py:909: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.12/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  return torch._C._get_cublas_allow_tf32()\n",
            "W1202 15:45:36.000000 263 torch/_inductor/utils.py:1558] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Acc: 0.9365 | F1: 0.9374 | Params: 0.35M | FLOPs: 49.24M | Inf: 5.68ms | Delta: -\n",
            "\n",
            "--- w/o Spectral Path ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-485098798.py:909: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/tmp/ipython-input-485098798.py:919: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInductorError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-485098798.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m             ablation_results, full_model_state = run_ablation_study(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-485098798.py\u001b[0m in \u001b[0;36mrun_ablation_study\u001b[0;34m(dataset_name, X_train, y_train, X_test, y_test, activity_names, device, epochs, freq_lr, other_lr)\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0minf_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasure_inference_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m         best_metrics, freq_history, phase_history = train_model_with_freq_lr(\n\u001b[0m\u001b[1;32m   1077\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-485098798.py\u001b[0m in \u001b[0;36mtrain_model_with_freq_lr\u001b[0;34m(model, train_loader, test_loader, device, epochs, freq_lr, other_lr, verbose)\u001b[0m\n\u001b[1;32m    921\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, *flat_args)\u001b[0m\n\u001b[1;32m   2302\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2303\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mimpl_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\u001b[0m in \u001b[0;36mimpl_fn\u001b[0;34m(double_ctx)\u001b[0m\n\u001b[1;32m   2288\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mimpl_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdouble_ctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2289\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompiledFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2290\u001b[0m                     return _backward_epilogue_functional(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\u001b[0m in \u001b[0;36m_backward_impl\u001b[0;34m(ctx, all_args)\u001b[0m\n\u001b[1;32m   2431\u001b[0m                         \u001b[0;31m# See Note: [Backward graph lazy lowering]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2432\u001b[0;31m                         CompiledFunction.compiled_bw = aot_config.bw_compiler(\n\u001b[0m\u001b[1;32m   2433\u001b[0m                             \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/schemas.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, gm, example_inputs)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     ) -> OutputCode:\n\u001b[0;32m-> 1251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/backends/common.py\u001b[0m in \u001b[0;36m_wrapped_bw_compiler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 return disable(\n\u001b[0;32m---> 82\u001b[0;31m                     disable(\n\u001b[0m\u001b[1;32m     83\u001b[0m                         \u001b[0mbw_compiler_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"do not trace backward compiler function\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_utils_internal.py\u001b[0m in \u001b[0;36mwrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mStrobelightCompileTimeProfiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py\u001b[0m in \u001b[0;36mbw_compiler\u001b[0;34m(gm, example_inputs)\u001b[0m\n\u001b[1;32m   2595\u001b[0m             ):\n\u001b[0;32m-> 2596\u001b[0;31m                 return compile_fx_backward(\n\u001b[0m\u001b[1;32m   2597\u001b[0m                     \u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py\u001b[0m in \u001b[0;36mcompile_fx_backward\u001b[0;34m(gm, example_inputs, compiler_config_extra, inner_compile)\u001b[0m\n\u001b[1;32m   2320\u001b[0m         ):\n\u001b[0;32m-> 2321\u001b[0;31m             return inner_compile(\n\u001b[0m\u001b[1;32m   2322\u001b[0m                 \u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py\u001b[0m in \u001b[0;36mcompile_fx_inner\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m         )\n\u001b[0;32m--> 782\u001b[0;31m         return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/repro/after_aot.py\u001b[0m in \u001b[0;36mdebug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# with fake inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0minner_compiled_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiler_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py\u001b[0m in \u001b[0;36m_compile_fx_inner\u001b[0;34m(gm, example_inputs, **graph_kwargs)\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                 raise InductorError(e, currentframe()).with_traceback(\n\u001b[0m\u001b[1;32m    991\u001b[0m                     \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py\u001b[0m in \u001b[0;36m_compile_fx_inner\u001b[0;34m(gm, example_inputs, **graph_kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m                 mb_compiled_graph = fx_codegen_and_compile(\n\u001b[0m\u001b[1;32m    975\u001b[0m                     \u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_to_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgraph_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py\u001b[0m in \u001b[0;36mfx_codegen_and_compile\u001b[0;34m(gm, example_inputs, inputs_to_check, **graph_kwargs)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodegen_and_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_to_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py\u001b[0m in \u001b[0;36mcodegen_and_compile\u001b[0;34m(self, gm, example_inputs, inputs_to_check, graph_kwargs)\u001b[0m\n\u001b[1;32m   1504\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m                             \u001b[0mcompiled_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_to_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m                             \u001b[0mcompiled_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py\u001b[0m in \u001b[0;36mcompile_to_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2318\u001b[0m         ):\n\u001b[0;32m-> 2319\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_to_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py\u001b[0m in \u001b[0;36m_compile_to_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueWithLineMap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2329\u001b[0;31m             \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_to_module_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2330\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFileBackedGraphModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py\u001b[0m in \u001b[0;36m_compile_to_module_lines\u001b[0;34m(self, wrapper_code)\u001b[0m\n\u001b[1;32m   2396\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdynamo_timed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PyCodeCache.load_by_key_path\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_pt2_compile_event\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2397\u001b[0;31m             mod = PyCodeCache.load_by_key_path(\n\u001b[0m\u001b[1;32m   2398\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/codecache.py\u001b[0m in \u001b[0;36mload_by_key_path\u001b[0;34m(cls, key, path, linemap, attrs)\u001b[0m\n\u001b[1;32m   3547\u001b[0m         \u001b[0min_toplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_toplevel_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3548\u001b[0;31m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reload_python_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_sys_modules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_toplevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/compile_tasks.py\u001b[0m in \u001b[0;36m_reload_python_module\u001b[0;34m(key, path, set_sys_modules)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset_sys_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/torchinductor_root/63/c63moymucvargmx22uaidfssuluhwumwuaifzpkuypp2g6xz63ag.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m \u001b[0masync_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1762\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0masync_compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/async_compile.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, scope)\u001b[0m\n\u001b[1;32m    630\u001b[0m             ):\n\u001b[0;32m--> 631\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_futures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/async_compile.py\u001b[0m in \u001b[0;36m_wait_futures\u001b[0;34m(self, scope)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m                 \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m                 \u001b[0mscope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/codecache.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4289\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/async_compile.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m()\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mSubprocException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInductorError\u001b[0m: SubprocException: An exception occurred in a subprocess:\n\nName=triton_red_fused_div_expand_native_dropout_backward_sum_unsqueeze_view_10\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_worker/subproc_pool.py\", line 397, in do_job\n    result = job()\n             ^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/compile_tasks.py\", line 66, in _worker_compile_triton\n    kernel.precompile(warm_cache_only=True)\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py\", line 439, in precompile\n    self._precompile_worker()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py\", line 474, in _precompile_worker\n    raise NoTritonConfigsError(\ntorch._inductor.runtime.triton_heuristics.NoTritonConfigsError: No valid triton configs. PTXASError: PTXAS error: `ptxas` failed with error code -2\n`ptxas` stderr:\n\nRepro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_75 /tmp/tmpr2qw93y6.ptx -o /tmp/tmpr2qw93y6.ptx.o\n\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-485098798.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1186\u001b[0m             \u001b[0mall_ablation_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mablation_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error processing {dataset_name}: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install thop ptflops\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from thop import profile\n",
        "from collections import Counter\n",
        "from glob import glob\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "import multiprocessing\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "def clean_state_dict(state_dict):\n",
        "    return {k: v for k, v in state_dict.items()\n",
        "            if 'total_ops' not in k and 'total_params' not in k}\n",
        "\n",
        "class UCIHARDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = torch.FloatTensor(data)\n",
        "        self.labels = torch.LongTensor(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "def read_txt_matrix(file_path):\n",
        "    return np.loadtxt(file_path)\n",
        "\n",
        "def load_uci_har(root_path='/content/drive/MyDrive/HAR_Dataset/UCI'):\n",
        "    UCI_CHANNELS_PREFIX = [\n",
        "        \"total_acc_x_\", \"total_acc_y_\", \"total_acc_z_\",\n",
        "        \"body_acc_x_\", \"body_acc_y_\", \"body_acc_z_\",\n",
        "        \"body_gyro_x_\", \"body_gyro_y_\", \"body_gyro_z_\",\n",
        "    ]\n",
        "    def load_split(split):\n",
        "        channels = []\n",
        "        for prefix in UCI_CHANNELS_PREFIX:\n",
        "            file_path = os.path.join(root_path, f\"{prefix}{split}.txt\")\n",
        "            if not os.path.exists(file_path):\n",
        "                raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "            channels.append(read_txt_matrix(file_path))\n",
        "        X = np.stack(channels, axis=1)\n",
        "        y = read_txt_matrix(os.path.join(root_path, f\"y_{split}.txt\")).astype(int) - 1\n",
        "        return X, y\n",
        "    X_train, y_train = load_split('train')\n",
        "    X_test, y_test = load_split('test')\n",
        "    X_train = X_train.transpose(0, 2, 1)\n",
        "    X_test = X_test.transpose(0, 2, 1)\n",
        "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train_flat)\n",
        "    X_train_flat = scaler.transform(X_train_flat)\n",
        "    X_test_flat = scaler.transform(X_test_flat)\n",
        "    X_train = X_train_flat.reshape(X_train.shape)\n",
        "    X_test = X_test_flat.reshape(X_test.shape)\n",
        "    activity_names = ['Walking', 'Walking Upstairs', 'Walking Downstairs', 'Sitting', 'Standing', 'Laying']\n",
        "    return X_train, y_train.astype(np.int64), X_test, y_test.astype(np.int64), activity_names\n",
        "\n",
        "def load_wisdm_data(dataset_path=\"/content/drive/MyDrive/HAR_Dataset/WISDM\"):\n",
        "    if os.path.isfile(dataset_path):\n",
        "        file_paths = [dataset_path]\n",
        "    else:\n",
        "        possible_files = ['WISDM_ar_v1.1_raw.txt', 'WISDM_ar_v1.1_trans.arff', 'wisdm-dataset.txt', 'actitracker_raw.txt']\n",
        "        file_paths = []\n",
        "        for filename in possible_files:\n",
        "            full_path = os.path.join(dataset_path, filename)\n",
        "            if os.path.exists(full_path):\n",
        "                file_paths.append(full_path)\n",
        "    if not file_paths:\n",
        "        return None, None, None, None, None\n",
        "    all_data = []\n",
        "    for file_path in file_paths:\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        cleaned_data = []\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            line = line.rstrip(';').rstrip(',')\n",
        "            if ',' in line:\n",
        "                parts = line.split(',')\n",
        "            elif ';' in line:\n",
        "                parts = line.split(';')\n",
        "            else:\n",
        "                continue\n",
        "            if len(parts) < 6:\n",
        "                continue\n",
        "            try:\n",
        "                user = parts[0].strip()\n",
        "                activity = parts[1].strip()\n",
        "                timestamp = parts[2].strip()\n",
        "                x_str = parts[3].strip()\n",
        "                y_str = parts[4].strip()\n",
        "                z_str = parts[5].strip()\n",
        "                if ';' in x_str:\n",
        "                    x_str = x_str.split(';')[0]\n",
        "                if ';' in y_str:\n",
        "                    y_str = y_str.split(';')[0]\n",
        "                if ';' in z_str:\n",
        "                    z_str = z_str.split(';')[0]\n",
        "                x = float(x_str)\n",
        "                y = float(y_str)\n",
        "                z = float(z_str)\n",
        "                cleaned_data.append([user, activity, timestamp, x, y, z])\n",
        "            except (ValueError, IndexError):\n",
        "                continue\n",
        "        if cleaned_data:\n",
        "            df = pd.DataFrame(cleaned_data, columns=['user', 'activity', 'timestamp', 'x', 'y', 'z'])\n",
        "            df['x'] = pd.to_numeric(df['x'], errors='coerce')\n",
        "            df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
        "            df['z'] = pd.to_numeric(df['z'], errors='coerce')\n",
        "            df = df.dropna()\n",
        "            all_data.append(df)\n",
        "    if not all_data:\n",
        "        return None, None, None, None, None\n",
        "    combined_df = pd.concat(all_data, ignore_index=True)\n",
        "    combined_df = combined_df.dropna()\n",
        "    combined_df = combined_df[combined_df['activity'].str.strip() != '']\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    groups = combined_df.groupby(['user', 'activity']) if 'user' in combined_df.columns else combined_df.groupby(['activity'])\n",
        "    window_size = 80\n",
        "    step = 40\n",
        "    for group_name, group_data in groups:\n",
        "        activity = group_name[-1] if isinstance(group_name, tuple) else group_name\n",
        "        acc_data = group_data[['x', 'y', 'z']].values.astype(np.float32)\n",
        "        if len(acc_data) < window_size:\n",
        "            continue\n",
        "        start = 0\n",
        "        while start + window_size <= len(acc_data):\n",
        "            window_data = acc_data[start:start + window_size, :]\n",
        "            all_windows.append(window_data)\n",
        "            all_labels.append(activity)\n",
        "            start += step\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    scaler = StandardScaler()\n",
        "    X_windowed_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_windowed_flat = scaler.fit_transform(X_windowed_flat)\n",
        "    X_windowed = X_windowed_flat.reshape(X_windowed.shape)\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(all_labels)\n",
        "    class_names = [str(label) for label in label_encoder.classes_]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    return X_train, y_train, X_test, y_test, class_names\n",
        "\n",
        "def load_dsads_data(data_path, w_s=25, stride=12):\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    activities = {\n",
        "        'a01': 'sitting', 'a02': 'standing', 'a03': 'lying on back',\n",
        "        'a04': 'lying on right side', 'a05': 'ascending stairs',\n",
        "        'a06': 'descending stairs', 'a07': 'standing in an elevator still',\n",
        "        'a08': 'moving around in an elevator', 'a09': 'walking in a parking lot',\n",
        "        'a10': 'walking on a treadmill with a speed of 4 kmh',\n",
        "        'a11': 'walking in flat and 15 deg inclined positions',\n",
        "        'a12': 'running on a treadmill with a speed of 8 kmh',\n",
        "        'a13': 'exercising on a stepper', 'a14': 'exercising on a cross trainer',\n",
        "        'a15': 'cycling on an exercise bike in horizontal positions',\n",
        "        'a16': 'cycling on an exercise bike in vertical positions',\n",
        "        'a17': 'rowing', 'a18': 'jumping', 'a19': 'playing basketball'\n",
        "    }\n",
        "    activity_codes = sorted(activities.keys())\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(activity_codes)\n",
        "    persons = ['p' + str(i) for i in range(1, 9)]\n",
        "    for person_str in persons:\n",
        "        for activity_str in activity_codes:\n",
        "            activity_label = label_encoder.transform([activity_str])[0]\n",
        "            pattern = os.path.join(data_path, activity_str, person_str, 's*.txt')\n",
        "            segment_files = sorted(glob(pattern))\n",
        "            if not segment_files:\n",
        "                continue\n",
        "            for f in segment_files[:11]:\n",
        "                try:\n",
        "                    segment_data = np.loadtxt(f, delimiter=',')\n",
        "                    if segment_data.shape[0] < w_s or segment_data.shape[1] < 45:\n",
        "                        continue\n",
        "                    segment_data = np.nan_to_num(segment_data, nan=0.0)\n",
        "                    start = 0\n",
        "                    while start + w_s <= segment_data.shape[0]:\n",
        "                        window_data = segment_data[start : start + w_s, :]\n",
        "                        all_windows.append(window_data)\n",
        "                        all_labels.append(activity_label)\n",
        "                        start += stride\n",
        "                except:\n",
        "                    continue\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    y_encoded = np.array(all_labels, dtype=int)\n",
        "    scaler = StandardScaler()\n",
        "    X_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_flat = scaler.fit_transform(X_flat)\n",
        "    X_windowed = X_flat.reshape(X_windowed.shape)\n",
        "    activity_names_sorted = [activities[code] for code in label_encoder.classes_]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    return X_train, y_train, X_test, y_test, activity_names_sorted\n",
        "\n",
        "def load_pamap2_data(dataset_dir=\"/content/drive/MyDrive/HAR_Dataset/PAMAP2\"):\n",
        "    file_paths = sorted(glob(os.path.join(dataset_dir, 'Protocol', 'subject*.dat')))\n",
        "    optional_path = os.path.join(dataset_dir, 'Optional')\n",
        "    if os.path.exists(optional_path):\n",
        "        file_paths += sorted(glob(os.path.join(optional_path, 'subject*.dat')))\n",
        "    if not file_paths:\n",
        "        return None, None, None, None, None\n",
        "    activity_labels = [\n",
        "        \"lying\", \"sitting\", \"standing\", \"walking\", \"running\", \"cycling\",\n",
        "        \"Nordic walking\", \"ascending stairs\", \"descending stairs\",\n",
        "        \"vacuum cleaning\", \"ironing\", \"rope jumping\"\n",
        "    ]\n",
        "    label_to_activity_idx = {\n",
        "        1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 12: 7, 13: 8, 16: 9, 17: 10, 24: 11\n",
        "    }\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    window_size = 100\n",
        "    step = 50\n",
        "    for file_path in file_paths:\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=r'\\s+', header=None, na_values='NaN')\n",
        "        except:\n",
        "            continue\n",
        "        df_cleaned = df.ffill().bfill()\n",
        "        if df_cleaned.empty:\n",
        "            continue\n",
        "        labels = df_cleaned.iloc[:, 1].values.astype(int)\n",
        "        all_sensor_cols = list(range(4, 10)) + list(range(21, 27)) + list(range(38, 44))\n",
        "        if df_cleaned.shape[1] < max(all_sensor_cols) + 1:\n",
        "            continue\n",
        "        features = df_cleaned.iloc[:, all_sensor_cols].values.astype(np.float32)\n",
        "        valid_indices = np.where(np.isin(labels, list(label_to_activity_idx.keys())))[0]\n",
        "        if len(valid_indices) == 0:\n",
        "            continue\n",
        "        features = features[valid_indices, :]\n",
        "        labels = labels[valid_indices]\n",
        "        if len(features) < window_size:\n",
        "            continue\n",
        "        start = 0\n",
        "        while start + window_size <= len(features):\n",
        "            window_data = features[start : start + window_size, :]\n",
        "            window_labels_raw = labels[start : start + window_size]\n",
        "            most_common_label = Counter(window_labels_raw).most_common(1)[0][0]\n",
        "            if most_common_label in label_to_activity_idx:\n",
        "                all_windows.append(window_data)\n",
        "                all_labels.append(label_to_activity_idx[most_common_label])\n",
        "            start += step\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    y_encoded = np.array(all_labels, dtype=int)\n",
        "    scaler = StandardScaler()\n",
        "    X_windowed_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_windowed_flat = scaler.fit_transform(X_windowed_flat)\n",
        "    X_windowed = X_windowed_flat.reshape(X_windowed.shape)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    return X_train, y_train, X_test, y_test, activity_labels\n",
        "\n",
        "def load_mhealth_data(dataset_dir=\"/content/drive/MyDrive/HAR_Dataset/MHEALTH\"):\n",
        "    if not os.path.exists(dataset_dir):\n",
        "        return None, None, None, None, None\n",
        "    subject_files = sorted([\n",
        "        os.path.join(dataset_dir, f)\n",
        "        for f in os.listdir(dataset_dir)\n",
        "        if f.startswith(\"mHealth_subject\") and f.endswith(\".log\")\n",
        "    ])\n",
        "    if not subject_files:\n",
        "        return None, None, None, None, None\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    window_size = 50\n",
        "    step = 25\n",
        "    for file_path in subject_files:\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=r'\\s+', header=None, engine='python', dtype=np.float32)\n",
        "            df = df.ffill().bfill()\n",
        "            if df.shape[1] < 24:\n",
        "                continue\n",
        "            labels = df.iloc[:, 23].values.astype(int)\n",
        "            imu_cols = [0, 1, 2] + list(range(5, 23))\n",
        "            features = df.iloc[:, imu_cols].values\n",
        "            valid_indices = np.where(labels != 0)[0]\n",
        "            if len(valid_indices) == 0:\n",
        "                continue\n",
        "            features = features[valid_indices, :]\n",
        "            labels = labels[valid_indices]\n",
        "            if len(features) < window_size:\n",
        "                continue\n",
        "            start = 0\n",
        "            while start + window_size <= len(features):\n",
        "                window_data = features[start : start + window_size, :]\n",
        "                window_labels_raw = labels[start : start + window_size]\n",
        "                most_common_label = Counter(window_labels_raw).most_common(1)[0][0]\n",
        "                all_windows.append(window_data)\n",
        "                all_labels.append(most_common_label)\n",
        "                start += step\n",
        "        except:\n",
        "            continue\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(all_labels)\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    scaler = StandardScaler()\n",
        "    X_windowed_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_windowed_flat = scaler.fit_transform(X_windowed_flat)\n",
        "    X_windowed = X_windowed_flat.reshape(X_windowed.shape)\n",
        "    mhealth_activity_mapping = {\n",
        "        1: 'Standing still', 2: 'Sitting and relaxing', 3: 'Lying down', 4: 'Walking',\n",
        "        5: 'Climbing stairs', 6: 'Waist bends forward', 7: 'Frontal elevation of arms',\n",
        "        8: 'Knees bending', 9: 'Cycling', 10: 'Jogging', 11: 'Running', 12: 'Jump front & back'\n",
        "    }\n",
        "    activity_labels = []\n",
        "    class_names = list(label_encoder.classes_)\n",
        "    for encoded_idx in range(len(class_names)):\n",
        "        original_label = class_names[encoded_idx]\n",
        "        activity_labels.append(mhealth_activity_mapping.get(original_label, f\"Unknown_Activity_{original_label}\"))\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    return X_train, y_train, X_test, y_test, activity_labels\n",
        "\n",
        "class MotionSenseLoader:\n",
        "    def __init__(self, frame_len, feature_name, N_classes):\n",
        "        self.feature_names = feature_name\n",
        "        self.N_Feature = len(feature_name)\n",
        "        self.frame_length = frame_len\n",
        "        self.hop_size = frame_len//2\n",
        "        self.N_classes = N_classes\n",
        "        self.label_encoder = OneHotEncoder(sparse_output=False)\n",
        "    def framing(self, signal):\n",
        "        shape = ((signal.shape[0] - self.frame_length) // self.hop_size + 1, self.frame_length)\n",
        "        strides = (signal.strides[0] * self.hop_size, signal.strides[0])\n",
        "        return np.lib.stride_tricks.as_strided(signal, shape=shape, strides=strides)\n",
        "    def create_label(self, label): return self.label_encoder.fit_transform(label)\n",
        "    def load_trainings_data(self, files, label_frame):\n",
        "        label = self.create_label(label_frame)\n",
        "        self.trainings_data, self.trainings_label = self.load_data(files, label)\n",
        "    def load_validation_data(self, files, label_frame):\n",
        "        label = self.label_encoder.transform(label_frame)\n",
        "        self.validation_data, self.validation_label = self.load_data(files, label)\n",
        "    def load_data(self, files, label):\n",
        "        feature_matrix, label_matrix = None, None\n",
        "        for i in range(len(files)):\n",
        "            try: tmp_data = pd.read_csv(files[i], engine='python')\n",
        "            except: continue\n",
        "            N_Blocks = 1+(np.shape(tmp_data)[0]-self.frame_length)//self.hop_size\n",
        "            if N_Blocks <= 0: continue\n",
        "            tmp_feature_mat = np.zeros((N_Blocks, self.frame_length, self.N_Feature))\n",
        "            tmp_label_vec = np.zeros((N_Blocks, self.N_classes))\n",
        "            for j in range(N_Blocks): tmp_label_vec[j, :] = label[i, :]\n",
        "            for idf, feat in enumerate(self.feature_names):\n",
        "                frame_matrix = self.framing(tmp_data[feat].to_numpy())\n",
        "                tmp_feature_mat[:, :, idf] = frame_matrix[:N_Blocks]\n",
        "            if feature_matrix is None:\n",
        "                feature_matrix = tmp_feature_mat\n",
        "                label_matrix = tmp_label_vec\n",
        "            else:\n",
        "                feature_matrix = np.append(feature_matrix, tmp_feature_mat, axis=0)\n",
        "                label_matrix = np.append(label_matrix, tmp_label_vec, axis=0)\n",
        "        return feature_matrix, label_matrix\n",
        "\n",
        "def load_motionsense_data(root_path='/content/drive/MyDrive/HAR_Dataset/MOTIONSENSE'):\n",
        "    files, label = [], []\n",
        "    for dirname, _, filenames in os.walk(root_path):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith('.csv') and not filename.startswith('.'):\n",
        "                full_path = os.path.join(dirname, filename)\n",
        "                if 'sub_' in filename:\n",
        "                    files.append(full_path)\n",
        "                    parent_dir = os.path.basename(os.path.dirname(full_path))\n",
        "                    if '_' in parent_dir: label.append(parent_dir.split('_')[0])\n",
        "                    else: files.pop()\n",
        "    if not files: return None, None, None, None, None\n",
        "    label_frame = pd.DataFrame(label, columns=['act'])\n",
        "    files_train, files_valid, y_train_raw, y_valid_raw = train_test_split(files, label_frame, test_size=0.2, random_state=0)\n",
        "    Feature = ['attitude.roll','attitude.pitch','attitude.yaw','gravity.x','gravity.y','gravity.z',\n",
        "               'rotationRate.x','rotationRate.y','rotationRate.z','userAcceleration.x','userAcceleration.y','userAcceleration.z']\n",
        "    N_classes = 6\n",
        "    loader = MotionSenseLoader(128, Feature, N_classes)\n",
        "    loader.load_trainings_data(files_train, y_train_raw)\n",
        "    loader.load_validation_data(files_valid, y_valid_raw)\n",
        "    X_train = loader.trainings_data.astype(np.float32).transpose(0, 2, 1)\n",
        "    X_test = loader.validation_data.astype(np.float32).transpose(0, 2, 1)\n",
        "    y_train = np.argmax(loader.trainings_label, axis=1)\n",
        "    y_test = np.argmax(loader.validation_label, axis=1)\n",
        "    activity_names = list(loader.label_encoder.categories_[0])\n",
        "    return X_train, y_train, X_test, y_test, activity_names\n",
        "\n",
        "def load_unimib_shar_data(dataset_dir=\"/content/drive/MyDrive/HAR_Dataset/UNIMIB\"):\n",
        "    train_path = os.path.join(dataset_dir, \"unimib_train.csv\")\n",
        "    test_path = os.path.join(dataset_dir, \"unimib_test.csv\")\n",
        "    val_path = os.path.join(dataset_dir, \"unimib_val.csv\")\n",
        "    if not os.path.exists(train_path): return None, None, None, None, None\n",
        "    def process_unimib_csv(path):\n",
        "        if not os.path.exists(path): return np.array([]), np.array([])\n",
        "        df = pd.read_csv(path)\n",
        "        df = df.sort_values(by=['ID', 't'])\n",
        "        X_list, y_list = [], []\n",
        "        for _, group in df.groupby('ID'):\n",
        "            X_list.append(group[['ax', 'ay', 'az']].values.astype(np.float32))\n",
        "            y_list.append(group['label'].iloc[0])\n",
        "        return np.array(X_list), np.array(y_list)\n",
        "    X_train, y_train_raw = process_unimib_csv(train_path)\n",
        "    X_test, y_test_raw = process_unimib_csv(test_path)\n",
        "    if os.path.exists(val_path):\n",
        "        X_val, y_val_raw = process_unimib_csv(val_path)\n",
        "        if len(X_val) > 0:\n",
        "            X_test = np.concatenate((X_test, X_val), axis=0)\n",
        "            y_test_raw = np.concatenate((y_test_raw, y_val_raw), axis=0)\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train_raw)\n",
        "    y_test = le.transform(y_test_raw)\n",
        "    class_names = [str(c) for c in le.classes_]\n",
        "    B_train, T, C = X_train.shape\n",
        "    B_test, _, _ = X_test.shape\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train.reshape(B_train, -1)).reshape(B_train, T, C).transpose(0, 2, 1)\n",
        "    X_test = scaler.transform(X_test.reshape(B_test, -1)).reshape(B_test, T, C).transpose(0, 2, 1)\n",
        "    return X_train, y_train, X_test, y_test, class_names\n",
        "\n",
        "class LearnedAdaptiveSpectralTransform(nn.Module):\n",
        "    def __init__(self, seq_len, in_channels, num_basis=64):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.in_channels = in_channels\n",
        "        self.num_basis = num_basis\n",
        "        self.register_buffer('t', torch.arange(seq_len).float())\n",
        "        low_band = num_basis // 3\n",
        "        mid_band = num_basis // 3\n",
        "        high_band = num_basis - low_band - mid_band\n",
        "        freqs_low = torch.linspace(0, seq_len//8, low_band) / seq_len\n",
        "        freqs_mid = torch.linspace(seq_len//8, seq_len//4, mid_band) / seq_len\n",
        "        freqs_high = torch.linspace(seq_len//4, seq_len//2, high_band) / seq_len\n",
        "        init_freqs = torch.cat([freqs_low, freqs_mid, freqs_high])\n",
        "        self.frequencies = nn.Parameter(init_freqs)\n",
        "        self.phases = nn.Parameter(torch.zeros(num_basis))\n",
        "        self.channel_weights_real = nn.Parameter(torch.randn(in_channels, num_basis) * 0.02)\n",
        "        self.channel_weights_imag = nn.Parameter(torch.randn(in_channels, num_basis) * 0.02)\n",
        "        self.gamma = nn.Parameter(torch.ones(in_channels, 1))\n",
        "        self.beta = nn.Parameter(torch.zeros(in_channels, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, T = x.shape\n",
        "        args = 2 * np.pi * self.frequencies.unsqueeze(1) * self.t.unsqueeze(0) + self.phases.unsqueeze(1)\n",
        "        basis_real = torch.cos(args)\n",
        "        basis_imag = -torch.sin(args)\n",
        "        spectral_real = torch.einsum('bct,ft->bcf', x, basis_real)\n",
        "        spectral_imag = torch.einsum('bct,ft->bcf', x, basis_imag)\n",
        "        weighted_real = spectral_real * (1 + self.channel_weights_real.unsqueeze(0)) - \\\n",
        "                       spectral_imag * self.channel_weights_imag.unsqueeze(0)\n",
        "        weighted_imag = spectral_real * self.channel_weights_imag.unsqueeze(0) + \\\n",
        "                       spectral_imag * (1 + self.channel_weights_real.unsqueeze(0))\n",
        "        spectral_mag = torch.sqrt(weighted_real**2 + weighted_imag**2 + 1e-8)\n",
        "        spectral_mag = spectral_mag / math.sqrt(self.seq_len)\n",
        "        spectral_mag = spectral_mag * self.gamma.unsqueeze(0) + self.beta.unsqueeze(0)\n",
        "        return spectral_mag\n",
        "\n",
        "class LinearAttention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=False)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, D = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, T, 3, self.num_heads, self.head_dim)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        q = F.elu(q) + 1\n",
        "        k = F.elu(k) + 1\n",
        "        kv = torch.einsum('bhnd,bhne->bhde', k, v)\n",
        "        out = torch.einsum('bhnd,bhde->bhne', q, kv)\n",
        "        z = torch.einsum('bhnd,bhd->bhn', q, k.sum(dim=2))\n",
        "        out = out / (z.unsqueeze(-1) + 1e-6)\n",
        "        out = out.transpose(1, 2).reshape(B, T, D)\n",
        "        out = self.proj(out)\n",
        "        return self.dropout(out)\n",
        "\n",
        "class SpectralAttention(nn.Module):\n",
        "    def __init__(self, num_basis, num_heads=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = num_basis // num_heads\n",
        "        self.qkv = nn.Linear(num_basis, num_basis * 3)\n",
        "        self.proj = nn.Linear(num_basis, num_basis)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = nn.LayerNorm(num_basis)\n",
        "        self.temperature = nn.Parameter(torch.ones(1) * math.sqrt(self.head_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, F_dim = x.shape\n",
        "        outputs = []\n",
        "        for c in range(C):\n",
        "            x_c = x[:, c, :]\n",
        "            x_norm = self.norm(x_c)\n",
        "            qkv = self.qkv(x_norm).reshape(B, 3, self.num_heads, self.head_dim).permute(1, 0, 2, 3)\n",
        "            q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "            attn = (q @ k.transpose(-2, -1)) / self.temperature\n",
        "            attn = F.softmax(attn, dim=-1)\n",
        "            attn = self.dropout(attn)\n",
        "            out = (attn @ v).reshape(B, F_dim)\n",
        "            out = self.proj(out)\n",
        "            out = self.dropout(out)\n",
        "            out = out + x_c\n",
        "            outputs.append(out)\n",
        "        return torch.stack(outputs, dim=1)\n",
        "\n",
        "class EnhancedCrossDomainFusion(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_heads=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.cross_attn1 = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.cross_attn2 = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm4 = nn.LayerNorm(hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, h_temporal, h_spectral):\n",
        "        attn_ts, _ = self.cross_attn1(self.norm1(h_temporal), self.norm2(h_spectral), h_spectral)\n",
        "        attn_st, _ = self.cross_attn2(self.norm3(h_spectral), self.norm4(h_temporal), h_temporal)\n",
        "        h_t = h_temporal + self.dropout(attn_ts)\n",
        "        h_s = h_spectral + self.dropout(attn_st)\n",
        "        pooled_t = h_t.mean(dim=1)\n",
        "        pooled_s = h_s.mean(dim=1)\n",
        "        gate_input = torch.cat([pooled_t, pooled_s], dim=-1)\n",
        "        gate_weight = self.gate(gate_input)\n",
        "        fused = gate_weight * pooled_t + (1 - gate_weight) * pooled_s\n",
        "        fused = fused + self.ffn(self.norm4(fused))\n",
        "        return fused\n",
        "\n",
        "class SimpleConcatFusion(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_heads=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, h_temporal, h_spectral):\n",
        "        pooled_t = h_temporal.mean(dim=1)\n",
        "        pooled_s = h_spectral.mean(dim=1)\n",
        "        concat = torch.cat([pooled_t, pooled_s], dim=-1)\n",
        "        fused = self.proj(concat)\n",
        "        fused = self.norm(fused)\n",
        "        fused = self.dropout(fused)\n",
        "        return fused\n",
        "\n",
        "class SimpleSumFusion(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_heads=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, h_temporal, h_spectral):\n",
        "        pooled_t = h_temporal.mean(dim=1)\n",
        "        pooled_s = h_spectral.mean(dim=1)\n",
        "        fused = pooled_t + pooled_s\n",
        "        fused = self.norm(fused)\n",
        "        fused = self.dropout(fused)\n",
        "        return fused\n",
        "\n",
        "class CrossAttentionOnlyFusion(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_heads=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.cross_attn1 = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.cross_attn2 = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm4 = nn.LayerNorm(hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, h_temporal, h_spectral):\n",
        "        attn_ts, _ = self.cross_attn1(self.norm1(h_temporal), self.norm2(h_spectral), h_spectral)\n",
        "        attn_st, _ = self.cross_attn2(self.norm3(h_spectral), self.norm4(h_temporal), h_temporal)\n",
        "        h_t = h_temporal + self.dropout(attn_ts)\n",
        "        h_s = h_spectral + self.dropout(attn_st)\n",
        "        pooled_t = h_t.mean(dim=1)\n",
        "        pooled_s = h_s.mean(dim=1)\n",
        "        fused = (pooled_t + pooled_s) / 2\n",
        "        return fused\n",
        "\n",
        "class EnhancedTemporalEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dim, num_heads=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, hidden_dim, 5, padding=2)\n",
        "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, 3, padding=1)\n",
        "        self.attn = LinearAttention(hidden_dim, num_heads, dropout)\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.conv1(x))\n",
        "        h = F.relu(self.conv2(h))\n",
        "        h = h.transpose(1, 2)\n",
        "        h_norm = self.norm1(h)\n",
        "        attn_out = self.attn(h_norm)\n",
        "        h = h + self.dropout(attn_out)\n",
        "        h = h + self.ffn(self.norm2(h))\n",
        "        return h\n",
        "\n",
        "class SingleScaleTemporalEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dim, num_heads=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, hidden_dim, 3, padding=1)\n",
        "        self.attn = LinearAttention(hidden_dim, num_heads, dropout)\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.conv1(x))\n",
        "        h = h.transpose(1, 2)\n",
        "        h_norm = self.norm1(h)\n",
        "        attn_out = self.attn(h_norm)\n",
        "        h = h + self.dropout(attn_out)\n",
        "        h = h + self.ffn(self.norm2(h))\n",
        "        return h\n",
        "\n",
        "class EnhancedParametricSpectralHAR(nn.Module):\n",
        "    def __init__(self, seq_len=128, in_channels=9, num_classes=6,\n",
        "                 num_basis=64, hidden_dim=128, num_heads=2, dropout=0.1,\n",
        "                 spectral_type='learnable', fusion_type='gated', temporal_type='multiscale'):\n",
        "        super().__init__()\n",
        "        self.spectral_type = spectral_type\n",
        "        self.fusion_type = fusion_type\n",
        "        self.temporal_type = temporal_type\n",
        "        if spectral_type == 'learnable':\n",
        "            self.spectral_operator = LearnedAdaptiveSpectralTransform(seq_len, in_channels, num_basis)\n",
        "        else:\n",
        "            self.spectral_operator = LearnedAdaptiveSpectralTransform(seq_len, in_channels, num_basis)\n",
        "        self.spectral_conv = nn.Sequential(\n",
        "            nn.Linear(num_basis, num_basis * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(num_basis * 2, num_basis)\n",
        "        )\n",
        "        self.spectral_attn = SpectralAttention(num_basis, num_heads, dropout)\n",
        "        self.spectral_proj = nn.Linear(num_basis, hidden_dim)\n",
        "        if temporal_type == 'multiscale':\n",
        "            self.temporal_encoder = EnhancedTemporalEncoder(in_channels, hidden_dim, num_heads, dropout)\n",
        "        else:\n",
        "            self.temporal_encoder = SingleScaleTemporalEncoder(in_channels, hidden_dim, num_heads, dropout)\n",
        "        if fusion_type == 'gated':\n",
        "            self.fusion = EnhancedCrossDomainFusion(hidden_dim, num_heads, dropout)\n",
        "        elif fusion_type == 'concat':\n",
        "            self.fusion = SimpleConcatFusion(hidden_dim, num_heads, dropout)\n",
        "        elif fusion_type == 'sum':\n",
        "            self.fusion = SimpleSumFusion(hidden_dim, num_heads, dropout)\n",
        "        elif fusion_type == 'cross_attn_only':\n",
        "            self.fusion = CrossAttentionOnlyFusion(hidden_dim, num_heads, dropout)\n",
        "        else:\n",
        "            self.fusion = EnhancedCrossDomainFusion(hidden_dim, num_heads, dropout)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        B, C, T = x.shape\n",
        "        spectral = self.spectral_operator(x)\n",
        "        spectral = self.spectral_conv(spectral)\n",
        "        spectral = self.spectral_attn(spectral)\n",
        "        spectral_pooled = spectral.mean(dim=1)\n",
        "        spectral_emb = self.spectral_proj(spectral_pooled).unsqueeze(1)\n",
        "        temporal = self.temporal_encoder(x)\n",
        "        spectral_expanded = spectral_emb.expand(B, temporal.size(1), -1)\n",
        "        fused = self.fusion(temporal, spectral_expanded)\n",
        "        logits = self.classifier(fused)\n",
        "        return logits\n",
        "\n",
        "    def get_frequency_params(self):\n",
        "        if hasattr(self.spectral_operator, 'frequencies'):\n",
        "            return self.spectral_operator.frequencies.detach().cpu().numpy()\n",
        "        return None\n",
        "\n",
        "    def get_phase_params(self):\n",
        "        if hasattr(self.spectral_operator, 'phases'):\n",
        "            return self.spectral_operator.phases.detach().cpu().numpy()\n",
        "        return None\n",
        "\n",
        "class TemporalOnlyModel(nn.Module):\n",
        "    def __init__(self, seq_len=128, in_channels=9, num_classes=6,\n",
        "                 hidden_dim=128, num_heads=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.temporal_encoder = EnhancedTemporalEncoder(in_channels, hidden_dim, num_heads, dropout)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        temporal = self.temporal_encoder(x)\n",
        "        pooled = temporal.mean(dim=1)\n",
        "        logits = self.classifier(pooled)\n",
        "        return logits\n",
        "\n",
        "class SpectralOnlyModel(nn.Module):\n",
        "    def __init__(self, seq_len=128, in_channels=9, num_classes=6,\n",
        "                 num_basis=64, hidden_dim=128, num_heads=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.spectral_operator = LearnedAdaptiveSpectralTransform(seq_len, in_channels, num_basis)\n",
        "        self.spectral_conv = nn.Sequential(\n",
        "            nn.Linear(num_basis, num_basis * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(num_basis * 2, num_basis)\n",
        "        )\n",
        "        self.spectral_attn = SpectralAttention(num_basis, num_heads, dropout)\n",
        "        self.spectral_proj = nn.Linear(num_basis, hidden_dim)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        spectral = self.spectral_operator(x)\n",
        "        spectral = self.spectral_conv(spectral)\n",
        "        spectral = self.spectral_attn(spectral)\n",
        "        spectral_pooled = spectral.mean(dim=1)\n",
        "        spectral_emb = self.spectral_proj(spectral_pooled)\n",
        "        logits = self.classifier(spectral_emb)\n",
        "        return logits\n",
        "\n",
        "class BaselineCNN(nn.Module):\n",
        "    def __init__(self, seq_len=128, in_channels=9, num_classes=6, hidden_dim=128, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, 64, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.conv3 = nn.Conv1d(128, hidden_dim, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool(x).squeeze(-1)\n",
        "        logits = self.classifier(x)\n",
        "        return logits\n",
        "\n",
        "class BaselineTransformer(nn.Module):\n",
        "    def __init__(self, seq_len=128, in_channels=9, num_classes=6, hidden_dim=128, num_heads=2, num_layers=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(in_channels, hidden_dim)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, seq_len, hidden_dim) * 0.02)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=hidden_dim * 2,\n",
        "            dropout=dropout,\n",
        "            activation='gelu',\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        x = self.input_proj(x)\n",
        "        x = x + self.pos_embedding[:, :T, :]\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1)\n",
        "        logits = self.classifier(x)\n",
        "        return logits\n",
        "\n",
        "def evaluate(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in test_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            logits = model(batch_x)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_y.cpu().numpy())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    return acc, f1, precision, recall\n",
        "\n",
        "def compute_flops_params(model, input_shape, device):\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, *input_shape).to(device)\n",
        "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
        "    flops_m = macs * 2 / 1e6\n",
        "    params_m = params / 1e6\n",
        "    return flops_m, params_m\n",
        "\n",
        "def measure_inference_time(model, input_shape, device, n_runs=100, warmup=10):\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, *input_shape).to(device)\n",
        "    with torch.no_grad():\n",
        "        for _ in range(warmup):\n",
        "            _ = model(dummy_input)\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.synchronize()\n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_runs):\n",
        "            _ = model(dummy_input)\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.synchronize()\n",
        "    end = time.time()\n",
        "    return (end - start) / n_runs * 1000\n",
        "\n",
        "def get_frequency_param_names(model):\n",
        "    freq_params = []\n",
        "    other_params = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'frequencies' in name or 'phases' in name:\n",
        "            freq_params.append(param)\n",
        "        else:\n",
        "            other_params.append(param)\n",
        "    return freq_params, other_params\n",
        "\n",
        "def train_model_with_freq_lr(model, train_loader, test_loader, device, epochs=50, freq_lr=0.01, other_lr=0.001, verbose=True):\n",
        "    try:\n",
        "        model = torch.compile(model)\n",
        "        if verbose: print(\"Model compiled with torch.compile()\")\n",
        "    except:\n",
        "        pass\n",
        "    freq_params, other_params = get_frequency_param_names(model)\n",
        "    if freq_params:\n",
        "        optimizer = torch.optim.AdamW([\n",
        "            {'params': freq_params, 'lr': freq_lr},\n",
        "            {'params': other_params, 'lr': other_lr}\n",
        "        ], weight_decay=1e-4)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    else:\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=other_lr, weight_decay=1e-4)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    best_acc = 0.0\n",
        "    best_metrics = {}\n",
        "    best_model_state = None\n",
        "    freq_history = []\n",
        "    phase_history = []\n",
        "    scaler = GradScaler()\n",
        "    if hasattr(model, 'get_frequency_params') and model.get_frequency_params() is not None:\n",
        "        freq_history.append(model.get_frequency_params().copy())\n",
        "        phase_history.append(model.get_phase_params().copy())\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            with autocast():\n",
        "                logits = model(batch_x)\n",
        "                loss = criterion(logits, batch_y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            total_loss += loss.item()\n",
        "        scheduler.step()\n",
        "        test_acc, test_f1, test_prec, test_rec = evaluate(model, test_loader, device)\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_metrics = {'acc': test_acc, 'f1': test_f1, 'prec': test_prec, 'rec': test_rec}\n",
        "            best_model_state = clean_state_dict(model.state_dict())\n",
        "\n",
        "        if hasattr(model, 'get_frequency_params') and model.get_frequency_params() is not None:\n",
        "            if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "                freq_history.append(model.get_frequency_params().copy())\n",
        "                phase_history.append(model.get_phase_params().copy())\n",
        "        if verbose and (epoch + 1) % 10 == 0:\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            print(f\"  Epoch {epoch+1}: Loss={total_loss/len(train_loader):.4f}, Acc={test_acc:.4f}, F1={test_f1:.4f}, LR={current_lr:.6f}\")\n",
        "    model.load_state_dict(best_model_state, strict=False)\n",
        "\n",
        "    return best_metrics, freq_history, phase_history\n",
        "\n",
        "def visualize_frequency_learning(dataset_name, freq_history, phase_history, seq_len, save_path=None):\n",
        "    if not freq_history or len(freq_history) < 2:\n",
        "        print(f\"  Not enough frequency history to visualize for {dataset_name}\")\n",
        "        return\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle(f'PSN Learning Dynamics Analysis - {dataset_name}', fontsize=16, fontweight='bold')\n",
        "\n",
        "    init_freqs = freq_history[0]\n",
        "    final_freqs = freq_history[-1]\n",
        "    freq_change = final_freqs - init_freqs\n",
        "\n",
        "    ax1 = axes[0, 0]\n",
        "    x = np.arange(len(init_freqs))\n",
        "    width = 0.35\n",
        "    ax1.bar(x - width/2, init_freqs * seq_len, width, label='Initial Config', alpha=0.6, color='gray')\n",
        "    ax1.bar(x + width/2, final_freqs * seq_len, width, label='Learned Config', alpha=0.8, color='blue')\n",
        "    ax1.set_xlabel('Basis Index', fontsize=10)\n",
        "    ax1.set_ylabel('Frequency Component (Hz)', fontsize=10)\n",
        "    ax1.set_title('Global Frequency Adaptation', fontsize=12, fontweight='bold')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.2)\n",
        "\n",
        "    ax2 = axes[0, 1]\n",
        "    colors = ['green' if c > 0 else 'red' for c in freq_change]\n",
        "    ax2.bar(x, freq_change * seq_len, color=colors, alpha=0.7)\n",
        "    ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "    ax2.set_xlabel('Basis Index', fontsize=10)\n",
        "    ax2.set_ylabel('Delta Frequency', fontsize=10)\n",
        "    ax2.set_title('Frequency Shift Magnitude', fontsize=12, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.2)\n",
        "\n",
        "    ax3 = axes[1, 0]\n",
        "    freq_array = np.array(freq_history) * seq_len\n",
        "    epochs_recorded = [0] + [i * 10 for i in range(1, len(freq_history))]\n",
        "    for i in range(0, len(init_freqs), max(1, len(init_freqs)//8)):\n",
        "        ax3.plot(epochs_recorded, freq_array[:, i], label=f'Basis {i}', linewidth=1.5, alpha=0.8)\n",
        "    ax3.set_xlabel('Training Epochs', fontsize=10)\n",
        "    ax3.set_ylabel('Frequency', fontsize=10)\n",
        "    ax3.set_title('Trajectory of Learnable Frequencies', fontsize=12, fontweight='bold')\n",
        "    ax3.legend(loc='upper right', fontsize=8, ncol=2)\n",
        "    ax3.grid(True, alpha=0.2)\n",
        "\n",
        "    ax4 = axes[1, 1]\n",
        "    if len(phase_history) >= 2:\n",
        "        init_phases = phase_history[0]\n",
        "        final_phases = phase_history[-1]\n",
        "        phase_change = final_phases - init_phases\n",
        "        phase_change = np.mod(phase_change + np.pi, 2 * np.pi) - np.pi\n",
        "        ax4.bar(x, phase_change, alpha=0.7, color='purple')\n",
        "        ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "        ax4.set_xlabel('Basis Index', fontsize=10)\n",
        "        ax4.set_ylabel('Phase Shift (radians)', fontsize=10)\n",
        "        ax4.set_title('Phase Adaptation', fontsize=12, fontweight='bold')\n",
        "        ax4.grid(True, alpha=0.2)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"  Visualization saved to {save_path}\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"\\n  [PSN Learning Statistics for {dataset_name}]\")\n",
        "    print(f\"    - Avg Abs Frequency Shift: {np.mean(np.abs(freq_change)) * seq_len:.4f} Hz\")\n",
        "    print(f\"    - Max Frequency Shift: {np.max(np.abs(freq_change)) * seq_len:.4f} Hz\")\n",
        "    print(f\"    - Basis Functions Adjusted Upwards: {np.mean(freq_change > 0) * 100:.1f}%\")\n",
        "\n",
        "def run_ablation_study(dataset_name, X_train, y_train, X_test, y_test, activity_names, device, epochs=50, freq_lr=0.001, other_lr=0.001):\n",
        "    seq_len = X_train.shape[1]\n",
        "    input_dim = X_train.shape[2]\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    train_dataset = UCIHARDataset(X_train, y_train)\n",
        "    test_dataset = UCIHARDataset(X_test, y_test)\n",
        "    num_workers = min(4, multiprocessing.cpu_count())\n",
        "    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n",
        "    ablation_configs = [\n",
        "        ('Full Model', {'spectral_type': 'learnable', 'fusion_type': 'gated', 'temporal_type': 'multiscale', 'model_type': 'full'}),\n",
        "        ('w/o Spectral Path', {'model_type': 'temporal_only'}),\n",
        "        ('w/o Temporal Path', {'model_type': 'spectral_only'}),\n",
        "        ('Simple Concatenation', {'spectral_type': 'learnable', 'fusion_type': 'concat', 'temporal_type': 'multiscale', 'model_type': 'full'}),\n",
        "        ('Simple Summation', {'spectral_type': 'learnable', 'fusion_type': 'sum', 'temporal_type': 'multiscale', 'model_type': 'full'}),\n",
        "        ('Cross-Attention Only', {'spectral_type': 'learnable', 'fusion_type': 'cross_attn_only', 'temporal_type': 'multiscale', 'model_type': 'full'}),\n",
        "        ('Single-scale CNN', {'spectral_type': 'learnable', 'fusion_type': 'gated', 'temporal_type': 'singlescale', 'model_type': 'full'}),\n",
        "    ]\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"ABLATION STUDY - {dataset_name}\")\n",
        "    print(f\"Frequency LR: {freq_lr}, Other LR: {other_lr}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    ablation_results = []\n",
        "    full_model_acc = None\n",
        "    full_model_state = None\n",
        "    full_model_freq_history = None\n",
        "    full_model_phase_history = None\n",
        "    for config_name, config in ablation_configs:\n",
        "        print(f\"\\n--- {config_name} ---\")\n",
        "        if config['model_type'] == 'temporal_only':\n",
        "            model = TemporalOnlyModel(\n",
        "                seq_len=seq_len,\n",
        "                in_channels=input_dim,\n",
        "                num_classes=num_classes,\n",
        "                hidden_dim=128,\n",
        "                num_heads=2,\n",
        "                dropout=0.2\n",
        "            ).to(device)\n",
        "        elif config['model_type'] == 'spectral_only':\n",
        "            model = SpectralOnlyModel(\n",
        "                seq_len=seq_len,\n",
        "                in_channels=input_dim,\n",
        "                num_classes=num_classes,\n",
        "                num_basis=64,\n",
        "                hidden_dim=128,\n",
        "                num_heads=2,\n",
        "                dropout=0.2\n",
        "            ).to(device)\n",
        "        else:\n",
        "            model = EnhancedParametricSpectralHAR(\n",
        "                seq_len=seq_len,\n",
        "                in_channels=input_dim,\n",
        "                num_classes=num_classes,\n",
        "                num_basis=64,\n",
        "                hidden_dim=128,\n",
        "                num_heads=2,\n",
        "                dropout=0.2,\n",
        "                spectral_type=config['spectral_type'],\n",
        "                fusion_type=config['fusion_type'],\n",
        "                temporal_type=config['temporal_type']\n",
        "            ).to(device)\n",
        "        flops_m, params_m = compute_flops_params(model, (seq_len, input_dim), device)\n",
        "        inf_time = measure_inference_time(model, (seq_len, input_dim), device)\n",
        "        best_metrics, freq_history, phase_history = train_model_with_freq_lr(\n",
        "            model, train_loader, test_loader, device,\n",
        "            epochs=epochs, freq_lr=freq_lr, other_lr=other_lr, verbose=False\n",
        "        )\n",
        "        if config_name == 'Full Model':\n",
        "            full_model_acc = best_metrics['acc']\n",
        "            full_model_state = clean_state_dict(model.state_dict())\n",
        "\n",
        "            full_model_freq_history = freq_history\n",
        "            full_model_phase_history = phase_history\n",
        "            delta = '-'\n",
        "        else:\n",
        "            delta = f\"{(best_metrics['acc'] - full_model_acc) * 100:.1f}%\"\n",
        "        print(f\"  Acc: {best_metrics['acc']:.4f} | F1: {best_metrics['f1']:.4f} | Params: {params_m:.2f}M | FLOPs: {flops_m:.2f}M | Inf: {inf_time:.2f}ms | Delta: {delta}\")\n",
        "        ablation_results.append({\n",
        "            'Dataset': dataset_name,\n",
        "            'Configuration': config_name,\n",
        "            'Acc': round(best_metrics['acc'], 4),\n",
        "            'F1': round(best_metrics['f1'], 4),\n",
        "            'Params(M)': round(params_m, 2),\n",
        "            'FLOPs(M)': round(flops_m, 2),\n",
        "            'Inf(ms)': round(inf_time, 2),\n",
        "            'Delta': delta\n",
        "        })\n",
        "    if full_model_freq_history:\n",
        "        print(f\"\\n--- Visualizing Learning Dynamics for {dataset_name} ---\")\n",
        "        visualize_frequency_learning(\n",
        "            dataset_name,\n",
        "            full_model_freq_history,\n",
        "            full_model_phase_history,\n",
        "            seq_len,\n",
        "            save_path=f'{dataset_name}_learning_dynamics.png'\n",
        "        )\n",
        "    return ablation_results, full_model_state\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"=\" * 80)\n",
        "    print(\"PSN (Parametric Spectral Network) Multi-Dataset Training & Analysis\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Device: {device}\\n\")\n",
        "    FREQ_LR = 0.001\n",
        "    OTHER_LR = 0.001\n",
        "    EPOCHS = 50\n",
        "    print(f\"Hyperparameters:\")\n",
        "    print(f\"  Frequency LR: {FREQ_LR}\")\n",
        "    print(f\"  Other LR: {OTHER_LR}\")\n",
        "    print(f\"  Epochs: {EPOCHS}\")\n",
        "    datasets_config = [\n",
        "        ('UCI-HAR', load_uci_har, '/content/drive/MyDrive/HAR_Dataset/UCI'),\n",
        "        #('WISDM', load_wisdm_data, '/content/drive/MyDrive/HAR_Dataset/WISDM'),\n",
        "        #('MotionSense', load_motionsense_data, '/content/drive/MyDrive/HAR_Dataset/MOTIONSENSE'),\n",
        "        #('UniMiB', load_unimib_shar_data, '/content/drive/MyDrive/HAR_Dataset/UNIMIB (1)'),\n",
        "        #('DSADS', load_dsads_data, '/content/drive/MyDrive/HAR_Dataset/DSADS'),\n",
        "        #('PAMAP2', load_pamap2_data, '/content/drive/MyDrive/HAR_Dataset/PAMAP2'),\n",
        "        #('MHEALTH', load_mhealth_data, '/content/drive/MyDrive/HAR_Dataset/MHEALTH')\n",
        "    ]\n",
        "    all_datasets = {}\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Loading Datasets\")\n",
        "    print(\"=\" * 80)\n",
        "    for dataset_name, loader_func, data_path in datasets_config:\n",
        "        try:\n",
        "            print(f\"\\n{'#'*60}\")\n",
        "            print(f\"Loading {dataset_name}...\")\n",
        "            print(f\"{'#'*60}\")\n",
        "            data = loader_func(data_path)\n",
        "            if data is None or data[0] is None:\n",
        "                print(f\"Failed to load {dataset_name}\")\n",
        "                continue\n",
        "            X_train, y_train, X_test, y_test, activity_names = data\n",
        "            num_train_classes = len(np.unique(y_train))\n",
        "            num_test_classes = len(np.unique(y_test))\n",
        "            print(f\"Train: {X_train.shape} | Classes: {num_train_classes}\")\n",
        "            print(f\"Test: {X_test.shape} | Classes: {num_test_classes}\")\n",
        "            print(f\"Activity Names: {activity_names}\")\n",
        "            train_class_dist = Counter(y_train)\n",
        "            test_class_dist = Counter(y_test)\n",
        "            print(f\"Train class distribution: {dict(sorted(train_class_dist.items()))}\")\n",
        "            print(f\"Test class distribution: {dict(sorted(test_class_dist.items()))}\")\n",
        "            all_datasets[dataset_name] = {\n",
        "                'X_train': X_train,\n",
        "                'y_train': y_train,\n",
        "                'X_test': X_test,\n",
        "                'y_test': y_test,\n",
        "                'activity_names': activity_names\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {dataset_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Successfully loaded {len(all_datasets)} datasets\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "    all_ablation_results = []\n",
        "    for dataset_name, dataset_data in all_datasets.items():\n",
        "        try:\n",
        "            ablation_results, full_model_state = run_ablation_study(\n",
        "                dataset_name,\n",
        "                dataset_data['X_train'],\n",
        "                dataset_data['y_train'],\n",
        "                dataset_data['X_test'],\n",
        "                dataset_data['y_test'],\n",
        "                dataset_data['activity_names'],\n",
        "                device,\n",
        "                epochs=EPOCHS,\n",
        "                freq_lr=FREQ_LR,\n",
        "                other_lr=OTHER_LR\n",
        "            )\n",
        "            all_ablation_results.extend(ablation_results)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {dataset_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    print(f\"\\n{'#'*80}\")\n",
        "    print(f\"{'#'*80}\")\n",
        "    print(\"FINAL SUMMARY\")\n",
        "    print(f\"{'#'*80}\")\n",
        "    print(f\"{'#'*80}\\n\")\n",
        "    if all_ablation_results:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"ABLATION STUDY RESULTS\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "        ablation_df = pd.DataFrame(all_ablation_results)\n",
        "        for dataset_name in ablation_df['Dataset'].unique():\n",
        "            print(f\"\\n--- {dataset_name} ---\")\n",
        "            dataset_ablation = ablation_df[ablation_df['Dataset'] == dataset_name]\n",
        "            print(dataset_ablation[['Configuration', 'Acc', 'F1', 'Params(M)', 'FLOPs(M)', 'Inf(ms)', 'Delta']].to_string(index=False))\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"EXPERIMENTS COMPLETED\")\n",
        "    print(f\"{'='*80}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w4KlwTRfZsDR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}